{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iminuit version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares\n",
    "import inspect\n",
    "\n",
    "import time\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_fit(f, x, y, sigma=None, p0=None, p0_lim=None):\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.ones_like(y)\n",
    "\n",
    "    init_params = {}\n",
    "    if not p0 is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[n]=p0[i]\n",
    "    if not p0_lim is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[\"limit_\"+n]=p0_lim[i]\n",
    "\n",
    "    least_squares = LeastSquares(x, y, sigma, f)\n",
    "\n",
    "    m = Minuit(least_squares, **init_params)\n",
    "\n",
    "    m.migrad()    \n",
    "    try:\n",
    "        cov = np.array(m.matrix())\n",
    "    except:\n",
    "        try:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "        except:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "        \n",
    "\n",
    "    return m.np_values(), cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_b1(positions, nominal_positions, b1_strategy = \"m\", outliers=0, plot=False):\n",
    "\n",
    "    nominal_step_size = nominal_positions[3] - nominal_positions[0]\n",
    "\n",
    "    if b1_strategy == \"c\":\n",
    "        pos_c   = positions[1::3]        \n",
    "    elif b1_strategy == \"m\":\n",
    "        pos_c = np.array( [ np.mean(positions[3*i:3*i+3]) for i in range(5)] ) \n",
    "    diffs =  np.diff( pos_c )\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if outliers == 0:\n",
    "        avg_step_size = np.mean( diffs )\n",
    "    else:\n",
    "        excluded_indices = []\n",
    "\n",
    "        diffs1  = np.array(diffs)\n",
    "        for i in range(outliers):\n",
    "            avg     = np.mean( diffs1 )\n",
    "            i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "            if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                break\n",
    "            excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "            diffs1 = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "        avg = np.mean(diffs1)\n",
    "        std = np.std(diffs1)\n",
    "        lim = 3*std\n",
    "        diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "        avg_step_size = np.mean(diffs2)\n",
    "\n",
    "        if plot:\n",
    "            plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "            plt.plot([-1,5], [avg, avg], \"-\", color=\"red\")\n",
    "            plt.fill_between([-1,5], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "            plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot([-1,5], [avg_step_size, avg_step_size], \"--g\")\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "    od_estimates = diffs - avg_step_size\n",
    "    new_stepsizes = od_estimates + nominal_step_size\n",
    "    new_positions = np.concatenate(([0], np.cumsum(new_stepsizes)))\n",
    "    # take the middle point as reference\n",
    "    new_positions = new_positions - new_positions[2] + nominal_positions[7]\n",
    "\n",
    "    return new_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_sep(positions, nominal_positions, steps_to_average=10, outliers=0, plot=False):\n",
    "\n",
    "    nominal_step_size = nominal_positions[1] - nominal_positions[0]\n",
    "\n",
    "    diffs = np.diff(positions)\n",
    "    diffs = diffs[ (np.arange(len(diffs)) % 3) != 2]\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if steps_to_average == 10:\n",
    "        if outliers == 0:\n",
    "            avg_step_size = np.mean( diffs )\n",
    "        else:\n",
    "            # remove 4 outliers\n",
    "            excluded_indices = []\n",
    "            diffs1  =np.array(diffs)\n",
    "            for i in range(outliers):\n",
    "                avg  = np.mean( diffs1 )\n",
    "                i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "                if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                    break\n",
    "                excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "                diffs1 = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "            avg = np.mean(diffs1)\n",
    "            std = np.std(diffs1)\n",
    "            lim = 3*std\n",
    "            diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "            avg_step_size = np.mean(diffs2)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "\n",
    "                plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "                plt.plot([-1,11], [avg, avg], \"-\", color=\"red\")\n",
    "                plt.fill_between([-1,11], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "                plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "                \n",
    "        if plot:\n",
    "            plt.plot([-1,11], [avg_step_size, avg_step_size], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "        od_estimates = diffs - avg_step_size\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "    elif steps_to_average == 2:\n",
    "\n",
    "        avg_step_sizes = np.repeat([ np.mean(diffs[2*i:2*i+2]) for i in range(5) ], 2)\n",
    "        od_estimates = diffs - avg_step_sizes\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "        if plot:\n",
    "            for i in range(5):\n",
    "                plt.plot(np.arange(len(avg_step_sizes))[2*i:2*i+2], avg_step_sizes[2*i:2*i+2], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "    # reference is always the middle point\n",
    "    result = np.repeat(nominal_positions[1::3], 3)*1.0\n",
    "    for i in range(len(result)):\n",
    "        if i%3==0:\n",
    "            result[i] -= new_stepsizes[i//3*2]\n",
    "        elif i%3==2:\n",
    "            result[i] += new_stepsizes[(i-2)//3*2+1]\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_stepsize_corr_b1(positions_b1, ls_b1_bpm_over_nominal, b1_strategy):\n",
    "    if b1_strategy == \"c\":\n",
    "        pos_c   = positions_b1[1::3]        \n",
    "    elif b1_strategy == \"m\":\n",
    "        pos_c = np.array( [ np.mean(positions_b1[3*i:3*i+3]) for i in range(5)] )\n",
    "    return pos_c * ls_b1_bpm_over_nominal\n",
    "\n",
    "\n",
    "def ls_stepsize_corr_sep(positions_b1, positions_b2, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal):\n",
    "    return positions_b1 * ls_b1_bpm_over_nominal - positions_b2 * ls_b2_bpm_over_nominal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfit_stepsize_corr_b1(positions_b1, nominal_positions_b1, b1_strategy):\n",
    "\n",
    "    nominal_pos_c = nominal_positions_b1[1::3]\n",
    "    if b1_strategy == \"c\":\n",
    "        bpm_pos_c   = positions_b1[1::3]        \n",
    "    elif b1_strategy == \"m\":\n",
    "        bpm_pos_c = np.array( [ np.mean(positions_b1[3*i:3*i+3]) for i in range(5)] )\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (bpm_pos_c[0] - bpm_pos_c[-1])/(nominal_pos_c[0] - nominal_pos_c[-1])\n",
    "    b0 = bpm_pos_c[0] - nominal_pos_c[0]*a0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, nominal_pos_c,  bpm_pos_c, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "    \n",
    "    # actually this would be better done the other way around\n",
    "    new_pos_b1 = nominal_pos_c + ( bpm_pos_c - (a*nominal_pos_c+b) )\n",
    "\n",
    "    return new_pos_b1\n",
    "\n",
    "\n",
    "def linfit_stepsize_corr_sep(separations, nominal_separations):\n",
    "   \n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (nominal_separations[0] - nominal_separations[-1])/(nominal_separations[0] - nominal_separations[-1])\n",
    "    b0 = nominal_separations[0] - nominal_separations[0]*a0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, nominal_separations,  separations, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    # actually this would be better done the other way around\n",
    "    new_separations = nominal_separations + ( separations - (a*nominal_separations+b) )\n",
    "\n",
    "    return new_separations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headon_position(rates, rate_unc, separations, beamspot_positions ):\n",
    "\n",
    "    def sg(x,a,m,s):\n",
    "        return a*np.exp(-0.5*((x-m)/s)**2)\n",
    "    \n",
    "    a0 = np.max(rates)\n",
    "    m0 = separations[1]\n",
    "    s0 = np.abs(separations[1] - separations[0])\n",
    "    popt_sg, pcov_sg = curve_fit(sg, separations, rates, sigma=rate_unc, \n",
    "                                    p0=[a0, m0, s0 ],\n",
    "                                    p0_lim = [\n",
    "                                        [a0/2, a0*2],\n",
    "                                        [m0-s0, m0+s0],\n",
    "                                        [s0/2, s0*2],\n",
    "                                    ] )\n",
    "\n",
    "    mu               = popt_sg[1]\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    popt_lin, pcov_lin = curve_fit(lin, separations, beamspot_positions, sigma=[params[\"beamspot_position_uncertainty\"]]*3, p0=[1, 0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    # compute result uncertainty\n",
    "    if np.allclose(pcov_lin, 0):\n",
    "        std = a*pcov_sg[1,1]**0.5\n",
    "    else:\n",
    "        mu_randomized = mu + pcov_sg[1,1]**0.5*np.random.normal(size=100)\n",
    "        try:\n",
    "            pcov_lin_sqrt = np.linalg.cholesky(pcov_lin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(pcov_lin)\n",
    "            sys.exit()\n",
    "\n",
    "        ab_randomized = popt_lin[:,np.newaxis] + np.einsum(\"ij,jk\", pcov_lin_sqrt, np.random.normal(size=(2,100)))\n",
    "        std = np.std( ab_randomized[0,:]*mu_randomized + ab_randomized[1,:] )\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1e-6\n",
    "\n",
    "    return a*mu+b, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsc(params):\n",
    "\n",
    "    ## nominal beampositions\n",
    "    nominal_B1_positions = np.repeat((np.arange(5)*params[\"nominal_step_size_B1\"]),3)\n",
    "    scan_pattern = np.tile([-params[\"nominal_step_size_B2\"], 0, params[\"nominal_step_size_B2\"]], 5)\n",
    "    nominal_B2_positions = nominal_B1_positions + scan_pattern\n",
    "\n",
    "    ## OD and BPM\n",
    "    if params[\"cumulative_OD\"]:\n",
    "        true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + np.cumsum(params[\"OD_B1\"])\n",
    "        true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + np.cumsum(params[\"OD_B2\"])\n",
    "    else:\n",
    "        true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + params[\"OD_B1\"]\n",
    "        true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + params[\"OD_B2\"]\n",
    "\n",
    "    doros_B1_positions = true_B1_positions / params[\"Doros_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Doros_noise_sigma\"] \n",
    "    doros_B2_positions = true_B2_positions / params[\"Doros_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Doros_noise_sigma\"]\n",
    "\n",
    "    arc_B1_positions = true_B1_positions / params[\"Arc_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "    arc_B2_positions = true_B2_positions / params[\"Arc_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "\n",
    "    avg_B1_positions = (doros_B1_positions + arc_B1_positions)/2\n",
    "    avg_B2_positions = (doros_B2_positions + arc_B2_positions)/2\n",
    "\n",
    "    ## OD correction of nominal\n",
    "\n",
    "    if params[\"pos_strategy\"]==\"nominal, middle point\":\n",
    "        analysis_separations   = nominal_B1_positions - nominal_B2_positions\n",
    "        analysis_B1_5positions = nominal_B1_positions[1::3]\n",
    "    elif params[\"pos_strategy\"]==\"nominal, avg point\":\n",
    "        analysis_separations   = nominal_B1_positions - nominal_B2_positions\n",
    "        analysis_B1_5positions = np.array([ np.mean(nominal_B1_positions[3*i:3*i+3]) for i in range(5)])\n",
    "    elif params[\"pos_strategy\"]==\"doros, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = doros_B1_positions[1::3]\n",
    "    elif params[\"pos_strategy\"]==\"doros, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = np.array([ np.mean(doros_B1_positions[3*i:3*i+3]) for i in range(5)])\n",
    "    #######################\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 2, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10 outlier4, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier 1, sep stepsize 10, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1)\n",
    "    #######################\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 2, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10 outlier4, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier 1, sep stepsize 10, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2)\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    ###########################\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    ###########################\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "    ###########################\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 0.5%, avg point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.005\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.005\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"m\")\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 0.5%, middle point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.005\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.005\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"c\")\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 1%, avg point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.01\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.01\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"m\")\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 1%, middle point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.01\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.01\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"c\")\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 0.25%, avg point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.0025\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.0025\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"m\")\n",
    "    elif params[\"pos_strategy\"]==\"doros, rel. ls based unc 0.25%, middle point\":\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*0.0025\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*0.0025\n",
    "        analysis_separations   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "        analysis_B1_5positions = ls_stepsize_corr_b1(doros_B1_positions, ls_b1_bpm_over_nominal, b1_strategy = \"c\")\n",
    "    #####################\n",
    "    elif params[\"pos_strategy\"]==\"doros, linfit b1, linfit b2, avg point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = linfit_stepsize_corr_sep(analysis_separations, nominal_B1_positions-nominal_B2_positions)\n",
    "        analysis_B1_5positions = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\" )\n",
    "    elif params[\"pos_strategy\"]==\"doros, linfit b1, linfit b2, middle point\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations   = linfit_stepsize_corr_sep(analysis_separations, nominal_B1_positions-nominal_B2_positions)\n",
    "        analysis_B1_5positions = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\" )\n",
    "\n",
    "\n",
    "\n",
    "    ## beamspot location \n",
    "    true_beamspot_positions = ( \n",
    "            true_B1_positions/params[\"Sigma_B1\"]**2 + \n",
    "            true_B2_positions/params[\"Sigma_B2\"]**2\n",
    "        )/(params[\"Sigma_B1\"]**-2+params[\"Sigma_B2\"]**-2)\n",
    "        \n",
    "    ## rates\n",
    "    true_rates       = np.exp(-0.5 * (true_B1_positions-true_B2_positions)**2 / (params[\"Sigma_B1\"]**2+params[\"Sigma_B2\"]**2) )\n",
    "    true_rates_unc   = true_rates**0.5 * np.max(true_rates)**0.5 * params[\"rate_runcertainty_at_head_on\"]\n",
    "\n",
    "    if params[\"randomize_rates\"]:\n",
    "        randomized_rates = true_rates + np.random.normal(size=true_rates_unc.shape) * true_rates_unc\n",
    "    else:\n",
    "        randomized_rates = true_rates\n",
    "\n",
    "    ## calculate head-on beamspot position\n",
    "    \n",
    "    computed_head_on_bs_position = []\n",
    "    computed_head_on_bs_position_unc = []\n",
    "    for i in range(5):\n",
    "\n",
    "        v, u = get_headon_position(\n",
    "            randomized_rates[3*i:3*i+3],\n",
    "            true_rates_unc[3*i:3*i+3],\n",
    "            analysis_separations[3*i:3*i+3],\n",
    "            true_beamspot_positions[3*i:3*i+3])\n",
    "\n",
    "        if not (np.isfinite(v) and np.isfinite(u)):\n",
    "            print(i)\n",
    "            print(u, v)\n",
    "            print([\n",
    "                randomized_rates[3*i:3*i+3],\n",
    "                true_rates_unc[3*i:3*i+3],\n",
    "                analysis_separations[3*i:3*i+3],\n",
    "                true_beamspot_positions[3*i:3*i+3]\n",
    "            ])\n",
    "            print(true_B1_positions-true_B2_positions)\n",
    "            print(analysis_separations)\n",
    "            sys.exit()\n",
    "\n",
    "        computed_head_on_bs_position.append(v) \n",
    "        computed_head_on_bs_position_unc.append(u)\n",
    "\n",
    "\n",
    "    ## fit linear function\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (computed_head_on_bs_position_unc[-1]-computed_head_on_bs_position_unc[0])/(analysis_B1_5positions[-1]-analysis_B1_5positions[0])\n",
    "    b0 = 0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, analysis_B1_5positions, computed_head_on_bs_position, sigma=computed_head_on_bs_position_unc, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    if not (np.isfinite(a) and np.isfinite(b)):\n",
    "        print(a, b)\n",
    "        print([\n",
    "            analysis_B1_5positions,\n",
    "            computed_head_on_bs_position,\n",
    "        ])\n",
    "        sys.exit()\n",
    "\n",
    "    return a, pcov_lin[0,0]**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(argv):\n",
    "\n",
    "    params, OD_distribution, cumulative_OD, pos_strategy, N, plot = argv\n",
    "\n",
    "    settings_txt = \"\\n\".join([\n",
    "        \"Settings:\",\n",
    "        \"position handling strategy:\\n  \" + \"\\n  \".join(pos_strategy.split(',')),\n",
    "        \"Nominal LS B1: {}\".format(params[\"Nominal_LS_B1\"]),\n",
    "        \"Nominal LS B2: {}\".format(params[\"Nominal_LS_B2\"]),\n",
    "        \"Doros LS B1: {}\".format(params[\"Doros_LS_B1\"]),\n",
    "        \"Doros LS B2: {}\".format(params[\"Doros_LS_B2\"]),\n",
    "        # \"Arc_LS_B1: {}\".format(params[\"Arc_LS_B1\"]),\n",
    "        # \"Arc_LS_B2: {}\".format(params[\"Arc_LS_B2\"]),\n",
    "        \"Sigma B1: {} um\".format(params[\"Sigma_B1\"]),\n",
    "        \"Sigma B2: {} um\".format(params[\"Sigma_B2\"]),\n",
    "        \"nominal step size B1: {} um\".format(params[\"nominal_step_size_B1\"]),\n",
    "        \"nominal step size B2: {} um\".format(params[\"nominal_step_size_B2\"]),\n",
    "        \"OD distribution: {}\".format(OD_distribution),\n",
    "        \"Markov Chain OD: {}\".format(cumulative_OD),\n",
    "        \"Doros noise_sigma: {} um\".format(params[\"Doros_noise_sigma\"]),\n",
    "        \"rate runcertainty at head on: {}%\".format(params[\"rate_runcertainty_at_head_on\"]*100),\n",
    "        \"randomize rates: {}\".format(params[\"randomize_rates\"]),\n",
    "        \"beamspot position uncertainty: {}\".format(params[\"beamspot_position_uncertainty\"]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    ls_results = []\n",
    "    ls_result_errs = []\n",
    "    for i in range(N):\n",
    "\n",
    "        if OD_distribution[0] == \"Normal\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            params.update(\n",
    "                {\n",
    "                    \"cumulative_OD\":cumulative_OD,\n",
    "                    \"OD_B1\":np.random.normal(size=15)*sigma_OD,\n",
    "                    \"OD_B2\":np.random.normal(size=15)*sigma_OD,\n",
    "                    \"pos_strategy\":pos_strategy,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalSum\":\n",
    "            p_OD = OD_distribution[1]\n",
    "            sigma1_OD = OD_distribution[2]\n",
    "            sigma2_OD = OD_distribution[3]\n",
    "            mask  = np.random.random(size=15)<p_OD\n",
    "            od_b1 = np.random.normal(size=15)*sigma1_OD * mask  + np.random.normal(size=15)*sigma2_OD * (1-mask)\n",
    "            mask  = np.random.random(size=15)<p_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma1_OD * mask  + np.random.normal(size=15)*sigma2_OD * (1-mask)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"cumulative_OD\":cumulative_OD,\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                    \"pos_strategy\":pos_strategy,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB1kick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b1[int(np.random.random()*15)] += OD_distribution[2]\n",
    "            params.update(\n",
    "                {\n",
    "                    \"cumulative_OD\":cumulative_OD,\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                    \"pos_strategy\":pos_strategy,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB2kick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2[int(np.random.random()*15)] += OD_distribution[2]\n",
    "            # print(od_b1)\n",
    "            # print(od_b2)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"cumulative_OD\":cumulative_OD,\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                    \"pos_strategy\":pos_strategy,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"CauchyLim\":\n",
    "            gamma_OD = OD_distribution[1]\n",
    "            lim = OD_distribution[2]\n",
    "\n",
    "            od_b1 = np.random.standard_cauchy(size=15)*gamma_OD\n",
    "            od_b1 = np.clip( od_b1, a_min=-lim, a_max=lim)\n",
    "            od_b2 = np.random.standard_cauchy(size=15)*gamma_OD\n",
    "            od_b2 = np.clip( od_b2, a_min=-lim, a_max=lim)\n",
    "\n",
    "            params.update(\n",
    "                {\n",
    "                    \"cumulative_OD\":cumulative_OD,\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                    \"pos_strategy\":pos_strategy,\n",
    "                })\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        # try:\n",
    "        ls, lse = lsc(params)\n",
    "        ls_results.append(ls)\n",
    "        ls_result_errs.append(lse)\n",
    "        # except RuntimeError as e:\n",
    "        #     print(e)\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        fig.patch.set_facecolor('white')\n",
    "        gs = gridspec.GridSpec(2,2)\n",
    "        # gs.update(hspace=0.1)\n",
    "\n",
    "        ax0  = fig.add_subplot(gs[0,0])\n",
    "        ax0.set_xlabel(\"LS\", fontsize=16)\n",
    "        ax1 = fig.add_subplot(gs[1,0])\n",
    "        ax1.set_xlabel(\"LS unc $\\\\times$ 100\", fontsize=16)\n",
    "        for ax in [ax0, ax1]:\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "            ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[:,1])   \n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax2.spines[axis].set_linewidth(0.0)\n",
    "        ax2.tick_params(\n",
    "                axis='both',          \n",
    "                which='both',     \n",
    "                bottom=False,      \n",
    "                top=False, \n",
    "                left=False,      \n",
    "                right=False,         \n",
    "                labelbottom=False,\n",
    "                labelleft=False)\n",
    "\n",
    "        \n",
    "\n",
    "        ax0.hist(ls_results, 50, density=False, facecolor='b', alpha=0.75)\n",
    "        ax1.hist(ls_result_errs*100, 50, density=False, facecolor='g', alpha=0.75)\n",
    "        # ax0.hist((np.array(ls_results)-1)*100, 50, density=False, facecolor='b', alpha=0.75)\n",
    "        # ax1.hist((np.array(ls_results)-1)*1000, 50, density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "\n",
    "        ax0.set_ylim(0, ax0.get_ylim()[1]*1.15)\n",
    "        ax0.text(0.02, 0.97, \"Mean: {:0.4f}$\\\\pm${:0.4f}\\nStd:{:0.4f}\".format(np.mean(ls_results), np.std(ls_results)/N**0.5, np.std(ls_results)),\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax0.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='bold',\n",
    "                        fontsize=14)\n",
    "\n",
    "        ax1.set_ylim(0, ax1.get_ylim()[1]*1.15)\n",
    "        ax1.text(0.02, 0.97, \"Mean: {:0.4f}$\\\\pm${:0.4f}\\nStd:{:0.4f}\".format(np.mean(ls_result_errs), np.std(ls_result_errs)/N**0.5,  np.std(ls_result_errs)),\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax1.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='bold',\n",
    "                        fontsize=14)\n",
    "\n",
    "        ax2.text(0.02, 0.97, settings_txt,\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax2.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='normal',\n",
    "                        fontsize=14)\n",
    "\n",
    "        fig.savefig(\"OD_{}_cumulative_{}_strategy_{}.png\".format(OD_distribution, cumulative_OD, pos_strategy))\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        return ls_results, ls_result_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    params = {\n",
    "        \"Nominal_LS_B1\":0.995,\n",
    "        \"Nominal_LS_B2\":0.99,\n",
    "        \"Doros_LS_B1\":1.005,\n",
    "        \"Doros_LS_B2\":1.01,\n",
    "        \"Arc_LS_B1\":1.005,\n",
    "        \"Arc_LS_B2\":1.01,\n",
    "        \"Sigma_B1\":90, #micron\n",
    "        \"Sigma_B2\":90, #micron\n",
    "        \"nominal_step_size_B1\": 130, #micron\n",
    "        \"nominal_step_size_B2\": 130, #micron\n",
    "        \"Doros_noise_sigma\":0.5, # micron\n",
    "        \"Arc_noise_sigma\":0, # micron\n",
    "        \"rate_runcertainty_at_head_on\":0.005, #relative\n",
    "        \"randomize_rates\":True,\n",
    "        \"beamspot_position_uncertainty\":1, #micron\n",
    "    }\n",
    "\n",
    "    worker([params, (\"NormalB2kick\", 2, 10), True, \"nominal, middle point\", 1, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 pools started\n"
     ]
    }
   ],
   "source": [
    "N = 4000\n",
    "parallel_execution = True\n",
    "\n",
    "params = {\n",
    "    \"Nominal_LS_B1\":0.9975,\n",
    "    \"Nominal_LS_B2\":0.995,\n",
    "    \"Doros_LS_B1\":1.0025,\n",
    "    \"Doros_LS_B2\":1.005,\n",
    "    \"Arc_LS_B1\":1.005,\n",
    "    \"Arc_LS_B2\":1.01,\n",
    "    \"Sigma_B1\":90, #micron\n",
    "    \"Sigma_B2\":90, #micron\n",
    "    \"nominal_step_size_B1\": 130, #micron\n",
    "    \"nominal_step_size_B2\": 130, #micron\n",
    "    \"Doros_noise_sigma\":0.25, # micron\n",
    "    \"Arc_noise_sigma\":0, # micron\n",
    "    \"rate_runcertainty_at_head_on\":0.005, #relative\n",
    "    \"randomize_rates\":True,\n",
    "    \"beamspot_position_uncertainty\":1, #micron\n",
    "}\n",
    "\n",
    "# Standard normal distribution 84.1% percentile --> +1 sigma\n",
    "# Standard Cauchy distribution 84.1% percentile --> ~ 2\n",
    "\n",
    "jobs = []\n",
    "for OD_distribution in [\n",
    "                            (\"Normal\", 0), (\"Normal\", 1), (\"Normal\", 2), (\"Normal\", 4), (\"Normal\", 8), (\"Normal\", 16),\n",
    "                            (\"NormalB1kick\", 2, 8), (\"NormalB2kick\", 2, 8),\n",
    "                            (\"NormalSum\", 0.9, 1, 4), (\"NormalSum\", 0.8, 1, 4),\n",
    "                            (\"NormalSum\", 0.9, 2, 8), (\"NormalSum\", 0.8, 2, 8),\n",
    "                            (\"CauchyLim\", 1, 20),  \n",
    "                            (\"Normal\", 2) \n",
    "                        ]:\n",
    "    for cumulative_OD in [False, True]:\n",
    "        for pos_strategy in [\n",
    "                                \"nominal, middle point\",\n",
    "                                \"nominal, avg point\",\n",
    "                                #\n",
    "                                \"doros, middle point\",\n",
    "                                \"doros, avg point\",\n",
    "                                #\n",
    "                                \"doros, b1 stepsize, sep stepsize 10, avg point\",\n",
    "                                \"doros, b1 stepsize, sep stepsize 2, avg point\",\n",
    "                                \"doros, b1 stepsize, sep stepsize 10 outlier4, avg point\",\n",
    "                                \"doros, b1 stepsize outlier 1, sep stepsize 10, avg point\",\n",
    "                                \"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, avg point\",\n",
    "                                \"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, avg point\",\n",
    "                                #\n",
    "                                \"doros, b1 stepsize, sep stepsize 10, middle point\",\n",
    "                                \"doros, b1 stepsize, sep stepsize 2, middle point\",\n",
    "                                \"doros, b1 stepsize, sep stepsize 10 outlier4, middle point\",\n",
    "                                \"doros, b1 stepsize outlier 1, sep stepsize 10, middle point\",\n",
    "                                \"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, middle point\",\n",
    "                                \"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, middle point\",\n",
    "                                #\n",
    "                                \"doros, b1 stepsize, avg point\",\n",
    "                                \"doros, b1 stepsize outlier1, avg point\",\n",
    "                                #\n",
    "                                \"doros, b1 stepsize, middle point\",\n",
    "                                \"doros, b1 stepsize outlier1, middle point\",\n",
    "                                #\n",
    "                                \"doros, rel. ls based unc 0.25%, avg point\",\n",
    "                                \"doros, rel. ls based unc 0.25%, middle point\",\n",
    "                                \"doros, rel. ls based unc 0.5%, avg point\",\n",
    "                                \"doros, rel. ls based unc 0.5%, middle point\",\n",
    "                                \"doros, rel. ls based unc 1%, avg point\",\n",
    "                                \"doros, rel. ls based unc 1%, middle point\",\n",
    "                                #\n",
    "                                \"doros, linfit b1, linfit b2, avg point\",\n",
    "                                \"doros, linfit b1, linfit b2, middle point\",\n",
    "                            ]:\n",
    "\n",
    "\n",
    "            if not parallel_execution:\n",
    "                worker([params, OD_distribution, cumulative_OD, pos_strategy, N, True])\n",
    "            else:\n",
    "                jobs.append([dict(params), OD_distribution, cumulative_OD, pos_strategy, N, True])   \n",
    "\n",
    "\n",
    "if parallel_execution:\n",
    "\n",
    "    threads_available = int(os.popen('grep -c cores /proc/cpuinfo').read())#/2\n",
    "    concurrent_jobs   = threads_available - 2\n",
    "\n",
    "    start = time.time()\n",
    "    pool = multiprocessing.Pool(processes=concurrent_jobs)\n",
    "    print(concurrent_jobs, \"pools started\")\n",
    "\n",
    "    for i, _ in enumerate(pool.imap_unordered(worker, jobs), 1):\n",
    "\n",
    "        if i>10:\n",
    "            eta_min = int(((len(jobs)-i)*(time.time()-start)/i)/60)\n",
    "            sys.stdout.write('\\rdone {0:%}, ETA: {1:d} mins  '.format(float(i)/len(jobs), eta_min))\n",
    "        elif i==0:\n",
    "            sys.stdout.write('done {0:%}'.format(float(i)/len(jobs)))\n",
    "        else:\n",
    "            sys.stdout.write('\\rdone {0:0.2%}'.format(float(i)/len(jobs)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    pool.close()\n",
    "    print(\"\\n\", (time.time()-start), \"sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
