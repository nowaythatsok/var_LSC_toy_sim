{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import traceback\n",
    "\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares\n",
    "import inspect\n",
    "\n",
    "import time\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_fit(f, x, y, sigma=None, p0=None, p0_lim=None):\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.ones_like(y)\n",
    "\n",
    "    init_params = {}\n",
    "    if not p0 is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[n]=p0[i]\n",
    "    if not p0_lim is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[\"limit_\"+n]=p0_lim[i]\n",
    "\n",
    "    least_squares = LeastSquares(x, y, sigma, f)\n",
    "\n",
    "    m = Minuit(least_squares, **init_params)\n",
    "\n",
    "    m.migrad()    \n",
    "    try:\n",
    "        cov = np.array(m.matrix())\n",
    "    except:\n",
    "        try:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "        except:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "           \n",
    "    return m.np_values(), cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_b1(positions, nominal_positions, outliers=0, od_ls=False, plot=False, r=1.0):\n",
    "\n",
    "    nominal_step_size = nominal_positions[3] - nominal_positions[0]\n",
    "    diffs =  np.diff( positions )\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if outliers == 0:\n",
    "        avg_step_size = np.mean( diffs )\n",
    "        od_std_b1     = np.std(diffs, ddof=1)\n",
    "    else:\n",
    "        excluded_indices = []\n",
    "\n",
    "        diffs1  = np.array(diffs)\n",
    "        for i in range(outliers):\n",
    "            avg     = np.mean( diffs1 )\n",
    "            i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "            diffs1_ = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "            if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                break\n",
    "            elif np.std(diffs1_, ddof=1)/np.std(diffs1, ddof=1) > r:\n",
    "                break\n",
    "            excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "            diffs1 = diffs1_\n",
    "        \n",
    "        avg = np.mean(diffs1)\n",
    "        std = np.std(diffs1, ddof=1)\n",
    "        od_std_b1 = std\n",
    "        lim = 3*std\n",
    "        diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "        avg_step_size = np.mean(diffs2)\n",
    "\n",
    "        if plot:\n",
    "            plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "            plt.plot([-1,5], [avg, avg], \"-\", color=\"red\")\n",
    "            plt.fill_between([-1,5], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "            plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot([-1,5], [avg_step_size, avg_step_size], \"--g\")\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "    od_estimates = diffs - avg_step_size\n",
    "    if od_ls:\n",
    "        od_estimates *= nominal_step_size/avg_step_size\n",
    "    new_stepsizes = od_estimates + nominal_step_size\n",
    "    new_positions = np.concatenate(([0], np.cumsum(new_stepsizes)))\n",
    "    # take the middle point as reference\n",
    "    new_positions = new_positions - new_positions[2] + nominal_positions[7]\n",
    "\n",
    "    return new_positions, od_std_b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_sep(positions, nominal_positions, steps_to_average=10, outliers=0, od_ls=False, plot=False, r=1.0):\n",
    "\n",
    "    nominal_step_size = nominal_positions[1] - nominal_positions[0]\n",
    "\n",
    "    diffs = np.diff(positions)\n",
    "    diffs = diffs[ (np.arange(len(diffs)) % 3) != 2]\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if steps_to_average == 10:\n",
    "        if outliers == 0:\n",
    "            avg_step_size = np.mean( diffs )\n",
    "            od_std_sep    = np.std(diffs, ddof=1)\n",
    "        else:\n",
    "            # remove 4 outliers\n",
    "            excluded_indices = []\n",
    "            diffs1  =np.array(diffs)\n",
    "            for i in range(outliers):\n",
    "                avg  = np.mean( diffs1 )\n",
    "                i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "                diffs1_ = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "                if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                    break\n",
    "                elif np.std(diffs1_, ddof=1)/np.std(diffs1, ddof=1) > r:\n",
    "                    break\n",
    "                excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "                diffs1 = diffs1_\n",
    "            avg = np.mean(diffs1)\n",
    "            std = np.std(diffs1, ddof=1)\n",
    "            od_std_sep = std\n",
    "            lim = 3*std\n",
    "            diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "            avg_step_size = np.mean(diffs2)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "\n",
    "                plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "                plt.plot([-1,11], [avg, avg], \"-\", color=\"red\")\n",
    "                plt.fill_between([-1,11], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "                plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "                \n",
    "        if plot:\n",
    "            plt.plot([-1,11], [avg_step_size, avg_step_size], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "        od_estimates = diffs - avg_step_size\n",
    "        if od_ls:\n",
    "            od_estimates *= nominal_step_size/avg_step_size\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "    elif steps_to_average == 2:\n",
    "\n",
    "        avg_step_sizes = np.repeat([ np.mean(diffs[2*i:2*i+2]) for i in range(5) ], 2)\n",
    "        od_estimates = diffs - avg_step_sizes\n",
    "        od_std_sep = np.std(od_estimates, ddof=1)\n",
    "        if od_ls:\n",
    "            od_estimates *= nominal_step_size/avg_step_sizes\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "        if plot:\n",
    "            for i in range(5):\n",
    "                plt.plot(np.arange(len(avg_step_sizes))[2*i:2*i+2], avg_step_sizes[2*i:2*i+2], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "    # reference is always the middle point\n",
    "    result = np.repeat(nominal_positions[1::3], 3)*1.0\n",
    "    for i in range(len(result)):\n",
    "        if i%3==0:\n",
    "            result[i] -= new_stepsizes[i//3*2]\n",
    "        elif i%3==2:\n",
    "            result[i] += new_stepsizes[(i-2)//3*2+1]\n",
    "    return result, od_std_sep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_stepsize_corr_b1(positions_b1, ls_b1_bpm_over_nominal):\n",
    "    return positions_b1 * ls_b1_bpm_over_nominal, 0\n",
    "\n",
    "\n",
    "def ls_stepsize_corr_sep(positions_b1, positions_b2, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal):\n",
    "    return positions_b1 * ls_b1_bpm_over_nominal - positions_b2 * ls_b2_bpm_over_nominal, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfit_stepsize_corr_b1(positions_b1, nominal_positions_b1, positions_b1_5p, n_fit=5, od_ls=False):\n",
    "\n",
    "    nominal_pos_5p = nominal_positions_b1[1::3]\n",
    "    if n_fit == 5:\n",
    "        fit_x   = nominal_pos_5p        \n",
    "        fit_y   = positions_b1_5p        \n",
    "    elif n_fit == 15:\n",
    "        fit_x   = nominal_positions_b1        \n",
    "        fit_y   = positions_b1\n",
    "    else:\n",
    "        raise ValueError(\"Unknown n_fit param \"+str(n_fit))\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (fit_y[0] - fit_y[-1])/(fit_x[0] - fit_x[-1])\n",
    "    b0 = fit_y[0] - fit_x[0]*a0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, fit_x,  fit_y, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "    \n",
    "    if not od_ls: # actually this would be better done the other way around\n",
    "        new_pos_b1 = nominal_pos_5p + ( positions_b1_5p - (a*nominal_pos_5p+b) )\n",
    "    else:\n",
    "        new_pos_b1 = (positions_b1_5p-b)/a\n",
    "\n",
    "    od_std_b1 = np.std(fit_y-lin(fit_x,a,b), ddof=1) * 1.41 # so that it is the same as the stepsize uncertainty in inf stat\n",
    "\n",
    "    return new_pos_b1, od_std_b1\n",
    "\n",
    "\n",
    "def linfit_stepsize_corr_sep(separations, nominal_separations, od_ls=False):\n",
    "   \n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (nominal_separations[0] - nominal_separations[-1])/(nominal_separations[0] - nominal_separations[-1])\n",
    "    b0 = nominal_separations[0] - nominal_separations[0]*a0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, nominal_separations,  separations, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    if not od_ls: # actually this would be better done the other way around\n",
    "        new_separations = nominal_separations + ( separations - (a*nominal_separations+b) )\n",
    "    else:\n",
    "        new_separations = (separations-b)/a\n",
    "\n",
    "    od_std_sep = np.std(separations-lin(nominal_separations,a,b), ddof=1) * 1.41 # so that it is the same as the stepsize uncertainty in inf stat\n",
    "\n",
    "    return new_separations, od_std_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headon_position_CMS(rates, rate_unc, separations, beamspot_positions, b1_position=None, bsp_unc=1 ):\n",
    "\n",
    "    def sg(x,a,m,s):\n",
    "        return a*np.exp(-0.5*((x-m)/s)**2)\n",
    "    \n",
    "    a0 = np.max(rates)\n",
    "    m0 = np.average(separations, weights=rates)\n",
    "    s0 = np.abs(separations[1] - separations[0])\n",
    "    popt_sg, pcov_sg = curve_fit(sg, separations, rates, sigma=rate_unc, \n",
    "                                    p0=[a0, m0, s0 ],\n",
    "                                    p0_lim = [\n",
    "                                        [a0/2, a0*2],\n",
    "                                        [m0-s0*3, m0+s0*3],\n",
    "                                        [s0/2, s0*2],\n",
    "                                    ] )\n",
    "\n",
    "    mu               = popt_sg[1]\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    popt_lin, pcov_lin = curve_fit(lin, separations, beamspot_positions, sigma=np.ones(3)*bsp_unc, p0=[1, 0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    # compute result uncertainty\n",
    "    if np.allclose(pcov_lin, 0):\n",
    "        std = a*pcov_sg[1,1]**0.5\n",
    "    else:\n",
    "        mu_randomized = mu + pcov_sg[1,1]**0.5*np.random.normal(size=100)\n",
    "        try:\n",
    "            pcov_lin_sqrt = np.linalg.cholesky(pcov_lin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(pcov_lin)\n",
    "            raise RuntimeError(\"Cannot perform Cholesky 1294\")\n",
    "\n",
    "        ab_randomized = popt_lin[:,np.newaxis] + np.einsum(\"ij,jk\", pcov_lin_sqrt, np.random.normal(size=(2,100)))\n",
    "        std = np.std( ab_randomized[0,:]*mu_randomized + ab_randomized[1,:], ddof=1 )\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1e-6\n",
    "\n",
    "    if not b1_position is None:\n",
    "        ######\n",
    "        # compute B1 position at head-on\n",
    "        popt_lin, pcov_lin = curve_fit(lin, separations, b1_position, sigma=np.ones(3), p0=[1, 0])\n",
    "        c = popt_lin[0]\n",
    "        d = popt_lin[1]\n",
    "\n",
    "        return a*mu+b, std, c*mu+d\n",
    "    else:\n",
    "        return a*mu+b, std, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headon_position_ATLAS(rates, rate_unc, separations, beamspot_positions, b1_position=None, bsp_unc=1 ):\n",
    "\n",
    "    beamspot_position_unc = np.ones(3)*bsp_unc\n",
    "\n",
    "    def sg(x,a,m,s):\n",
    "        return a*np.exp(-0.5*((x-m)/s)**2)\n",
    "\n",
    "    def dsg_dx(x,a,m,s):\n",
    "        return -(x-m)/s**2*sg(x,a,m,s)\n",
    "\n",
    "    a0 = np.max(rates)\n",
    "    m0 = np.average(beamspot_positions, weights=rates)\n",
    "    s0 = np.abs(beamspot_positions[1] - beamspot_positions[0])\n",
    "    popt_sg, pcov_sg = curve_fit(sg, beamspot_positions, rates, sigma=rate_unc, \n",
    "                                    p0=[a0, m0, s0 ],\n",
    "                                    p0_lim = [\n",
    "                                        [a0/2, a0*2],\n",
    "                                        [m0-s0*3, m0+s0*3],\n",
    "                                        [s0/2, s0*2],\n",
    "                                    ] )\n",
    "    a1 = popt_sg[0]\n",
    "    m1 = popt_sg[1]\n",
    "    s1 = popt_sg[2]\n",
    "    combined_unc = (rate_unc**2 + (dsg_dx(beamspot_positions, a1,m1,s1)*beamspot_position_unc)**2)**0.5 \n",
    "    popt_sg, pcov_sg = curve_fit(sg, beamspot_positions, rates, sigma=combined_unc, \n",
    "                                    p0=[a1, m1, s1 ],\n",
    "                                    p0_lim = [\n",
    "                                        [a1/2, a1*2],\n",
    "                                        [m1-s1*3, m1+s1*3],\n",
    "                                        [s1/2, s1*2],\n",
    "                                    ] )                           \n",
    "\n",
    "    mu              = popt_sg[1]\n",
    "    mu_unc          = pcov_sg[1,1]**0.5\n",
    "\n",
    "    if not b1_position is None:\n",
    "        ######\n",
    "        # compute B1 position at head-on\n",
    "\n",
    "        # for nominal this fit would not work for example-->special case\n",
    "        if np.abs(b1_position[-1]-b1_position[0]) < 0.1*np.abs(beamspot_positions[-1] - beamspot_positions[0]):\n",
    "            return  mu, mu_unc, np.mean(b1_position)\n",
    "\n",
    "        a0 = np.max(rates)\n",
    "        m0 = np.average(b1_position, weights=rates)\n",
    "        s0 = np.abs(b1_position[1] - b1_position[0])\n",
    "        popt_sg, pcov_sg = curve_fit(sg, b1_position, rates, sigma=rate_unc, \n",
    "                                        p0=[a0, m0, s0 ],\n",
    "                                        p0_lim = [\n",
    "                                            [a0/2, a0*2],\n",
    "                                            [m0-s0*3, m0+s0*3],\n",
    "                                            [s0/2, s0*2],\n",
    "                                        ] )\n",
    "        mu_b1 = popt_sg[1]\n",
    "\n",
    "        return  mu, mu_unc, mu_b1\n",
    "    else:\n",
    "        return mu, mu_unc, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsc(params):\n",
    "\n",
    "    ## nominal beampositions\n",
    "    nominal_B1_positions = np.repeat((np.arange(5)*params[\"nominal_step_size_B1\"]),3)\n",
    "    scan_pattern = np.tile([-params[\"nominal_step_size_B2\"], 0, params[\"nominal_step_size_B2\"]], 5)\n",
    "    nominal_B2_positions = nominal_B1_positions + scan_pattern\n",
    "\n",
    "    ## OD and BPM\n",
    "    if params[\"cumulative_OD\"]:\n",
    "        true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + np.cumsum(params[\"OD_B1\"])\n",
    "        true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + np.cumsum(params[\"OD_B2\"])\n",
    "    else:\n",
    "        true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + params[\"OD_B1\"]\n",
    "        true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + params[\"OD_B2\"]\n",
    "\n",
    "    doros_B1_positions = true_B1_positions / params[\"Doros_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Doros_noise_sigma\"] \n",
    "    doros_B2_positions = true_B2_positions / params[\"Doros_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Doros_noise_sigma\"]\n",
    "\n",
    "    # arc_B1_positions = true_B1_positions / params[\"Arc_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "    # arc_B2_positions = true_B2_positions / params[\"Arc_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "\n",
    "    # avg_B1_positions = (doros_B1_positions + arc_B1_positions)/2\n",
    "    # avg_B2_positions = (doros_B2_positions + arc_B2_positions)/2\n",
    "\n",
    "    ## try a data drive OD estimation\n",
    "    od_std_b1_full_naiive = np.std(doros_B1_positions - nominal_B1_positions, ddof=1)\n",
    "    od_std_b2_full_naiive = np.std(doros_B2_positions - nominal_B2_positions, ddof=1)\n",
    "    od_std_b1_full_naiive2 = np.std(np.diff(doros_B1_positions - nominal_B1_positions), ddof=1)\n",
    "    od_std_b2_full_naiive2 = np.std(np.diff(doros_B2_positions - nominal_B2_positions), ddof=1)\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    popt_lin, pcov_lin = curve_fit(lin, nominal_B1_positions,  doros_B1_positions, p0=[1, 0])\n",
    "    od_std_b1_full_fit = np.std(doros_B1_positions - lin(nominal_B1_positions, *popt_lin), ddof=1)\n",
    "\n",
    "    popt_lin, pcov_lin = curve_fit(lin, nominal_B2_positions,  doros_B2_positions, p0=[1, 0])\n",
    "    od_std_b2_full_fit = np.std(doros_B2_positions - lin(nominal_B2_positions, *popt_lin), ddof=1)\n",
    "\n",
    "\n",
    "    ## beamspot location \n",
    "    true_beamspot_positions = ( \n",
    "            true_B1_positions/params[\"Sigma_B1\"]**2 + \n",
    "            true_B2_positions/params[\"Sigma_B2\"]**2\n",
    "        )/(params[\"Sigma_B1\"]**-2+params[\"Sigma_B2\"]**-2)\n",
    "\n",
    "    if params[\"randomize_beamspot_position\"]:\n",
    "        randomized_beamspot_positions = true_beamspot_positions + np.random.normal(size=true_beamspot_positions.shape) * params[\"beamspot_position_uncertainty\"]\n",
    "    else:\n",
    "        randomized_beamspot_positions = true_beamspot_positions\n",
    "        \n",
    "    ## rates\n",
    "    true_rates       = np.exp(-0.5 * (true_B1_positions-true_B2_positions)**2 / (params[\"Sigma_B1\"]**2+params[\"Sigma_B2\"]**2) )\n",
    "    true_rates_unc   = true_rates**0.5 * np.max(true_rates)**0.5 * params[\"rate_runcertainty_at_head_on\"]\n",
    "\n",
    "    if params[\"randomize_rates\"]:\n",
    "        randomized_rates = true_rates + np.random.normal(size=true_rates_unc.shape) * true_rates_unc\n",
    "    else:\n",
    "        randomized_rates = true_rates\n",
    "\n",
    "\n",
    "    ##################### Analysis\n",
    "\n",
    "    if params[\"pos_strategy\"].startswith(\"doros, rel. ls based unc\"):\n",
    "        if \"0.1%\" in params[\"pos_strategy\"]:\n",
    "            ls_sigma = 0.001\n",
    "        elif \"0.25%\" in params[\"pos_strategy\"]:\n",
    "            ls_sigma = 0.0025\n",
    "        elif \"0.5%\" in params[\"pos_strategy\"]:\n",
    "            ls_sigma = 0.005\n",
    "        elif \"1%\" in params[\"pos_strategy\"]:\n",
    "            ls_sigma = 0.01\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected ls unc.\")\n",
    "        ls_b1_bpm_over_nominal = params[\"Doros_LS_B1\"] / params[\"Nominal_LS_B1\"] + np.random.normal()*ls_sigma\n",
    "        ls_b2_bpm_over_nominal = params[\"Doros_LS_B2\"] / params[\"Nominal_LS_B2\"] + np.random.normal()*ls_sigma\n",
    "\n",
    "    ## OD correction of separations\n",
    "    if params[\"sep_strategy\"]==\"nominal\":\n",
    "        analysis_separations   = nominal_B1_positions - nominal_B2_positions\n",
    "        diffs = np.diff(doros_B1_positions - doros_B2_positions)\n",
    "        diffs = diffs[ (np.arange(len(diffs)) % 3) != 2]\n",
    "        od_std_sep = np.std(diffs, ddof=1)\n",
    "    ###\n",
    "    elif params[\"sep_strategy\"]==\"doros\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        diffs = np.diff(analysis_separations)\n",
    "        diffs = diffs[ (np.arange(len(diffs)) % 3) != 2]\n",
    "        od_std_sep = np.std(diffs, ddof=1)\n",
    "    ###\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize2\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier2\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier2_0.50\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2, r=0.5)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier4\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier4_0.50\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4, r=0.5)\n",
    "    ###\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0, od_ls=True)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize2, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0, od_ls=True)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier2, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2, od_ls=True)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier2_0.50, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2, od_ls=True, r=0.5)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier4, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4, od_ls=True)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep stepsize10 outlier4_0.50, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4, od_ls=True, r=0.5)\n",
    "    ###\n",
    "    elif params[\"sep_strategy\"].startswith(\"doros, rel. ls based unc\"):  \n",
    "        analysis_separations, od_std_sep   = ls_stepsize_corr_sep(doros_B1_positions, doros_B2_positions, ls_b1_bpm_over_nominal, ls_b2_bpm_over_nominal)\n",
    "    ###\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep linfit\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = linfit_stepsize_corr_sep(analysis_separations, nominal_B1_positions-nominal_B2_positions)\n",
    "    elif params[\"sep_strategy\"]==\"doros, sep linfit, od_ls\":\n",
    "        analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "        analysis_separations, od_std_sep   = linfit_stepsize_corr_sep(analysis_separations, nominal_B1_positions-nominal_B2_positions, od_ls=True )\n",
    "    else:\n",
    "        raise Exception(\"Sep strategy unknown \"+params[\"sep_strategy\"])   \n",
    "\n",
    "    \n",
    "\n",
    "    ## calculate head-on beamspot position\n",
    "\n",
    "    doros_B1_5positions_fit         = []\n",
    "    computed_head_on_bs_position    = []\n",
    "    computed_head_on_bs_position_unc= []\n",
    "    for i in range(5):\n",
    "\n",
    "        doros_B1_3positions = None\n",
    "        if params[\"miniscan_b1_strategy\"]==\"fit\":\n",
    "            doros_B1_3positions = doros_B1_positions[3*i:3*i+3]\n",
    "\n",
    "        if params[\"headon_determination_method\"] == \"CMS\":\n",
    "            v, u, w = get_headon_position_CMS(\n",
    "                randomized_rates[3*i:3*i+3],\n",
    "                true_rates_unc[3*i:3*i+3],\n",
    "                analysis_separations[3*i:3*i+3],\n",
    "                randomized_beamspot_positions[3*i:3*i+3],\n",
    "                doros_B1_3positions,\n",
    "                params[\"beamspot_position_uncertainty\"])\n",
    "\n",
    "            doros_B1_5positions_fit.append(w)\n",
    "\n",
    "        elif params[\"headon_determination_method\"] == \"ATLAS\":\n",
    "            v, u, w = get_headon_position_ATLAS(\n",
    "                randomized_rates[3*i:3*i+3],\n",
    "                true_rates_unc[3*i:3*i+3],\n",
    "                analysis_separations[3*i:3*i+3],\n",
    "                randomized_beamspot_positions[3*i:3*i+3],\n",
    "                None,\n",
    "                params[\"beamspot_position_uncertainty\"])\n",
    "\n",
    "            doros_B1_5positions_fit.append(w)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown headon_determination_method \" + params[\"headon_determination_method\"])\n",
    "\n",
    "        if not (np.isfinite(v) and np.isfinite(u)):\n",
    "            print(params[\"headon_determination_method\"])\n",
    "            print(i)\n",
    "            print(u, v)\n",
    "            print([\n",
    "                randomized_rates[3*i:3*i+3],\n",
    "                true_rates_unc[3*i:3*i+3],\n",
    "                analysis_separations[3*i:3*i+3],\n",
    "                randomized_beamspot_positions[3*i:3*i+3],\n",
    "                doros_B1_positions[3*i:3*i+3],\n",
    "                params[\"beamspot_position_uncertainty\"]\n",
    "            ])\n",
    "            print(true_B1_positions-true_B2_positions)\n",
    "            print(analysis_separations)\n",
    "            raise RuntimeError(\"u or v not finite 897\")\n",
    "\n",
    "        computed_head_on_bs_position.append(v) \n",
    "        computed_head_on_bs_position_unc.append(u)\n",
    "\n",
    "    doros_B1_5positions_fit = np.array(doros_B1_5positions_fit)\n",
    "\n",
    "\n",
    "    # B1 handling and corrections\n",
    "    if params[\"b1_strategy\"] == \"nominal\":\n",
    "        analysis_B1_5positions = nominal_B1_positions[1::3]\n",
    "        od_std_b1 = np.std(np.diff([ np.mean(doros_B1_positions[3*i:3*i+3]) for i in range(5)]), ddof=1)\n",
    "    else:\n",
    "        if params[\"miniscan_b1_strategy\"]==\"avg\":\n",
    "            doros_B1_5positions   = np.array([ np.mean(doros_B1_positions[3*i:3*i+3]) for i in range(5)])\n",
    "        elif params[\"miniscan_b1_strategy\"]==\"middle\":\n",
    "            doros_B1_5positions   = doros_B1_positions[1::3]\n",
    "        elif params[\"miniscan_b1_strategy\"]==\"fit\":\n",
    "            doros_B1_5positions   = doros_B1_5positions_fit\n",
    "        else:\n",
    "            raise Exception(\"Miniscan b1 strategy unknown \"+params[\"miniscan_b1_strategy\"]) \n",
    "    \n",
    "        if params[\"b1_strategy\"] == \"doros\":\n",
    "            analysis_B1_5positions = doros_B1_5positions\n",
    "            od_std_b1 = np.std(np.diff(doros_B1_5positions), ddof=1)\n",
    "        ###\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=0)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier1\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=1)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier1_0.35\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=1, r=0.35)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier2\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=2)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier2_0.35\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=2, r=0.35)\n",
    "        ###\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=0, od_ls = True)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier1, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=1, od_ls = True)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier1_0.35, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=1, od_ls = True, r=0.35)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier2, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=2, od_ls = True)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 stepsize outlier2_0.35, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = avg_stepsize_corr_b1(doros_B1_5positions, nominal_B1_positions, outliers=2, od_ls = True, r=0.35)\n",
    "        ###\n",
    "        elif params[\"b1_strategy\"].startswith(\"doros, rel. ls based unc\"): \n",
    "            analysis_B1_5positions, od_std_b1 = ls_stepsize_corr_b1(doros_B1_5positions, ls_b1_bpm_over_nominal)\n",
    "        ###\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 linfit5\":\n",
    "            analysis_B1_5positions, od_std_b1 = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, doros_B1_5positions, n_fit=5 )\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 linfit5, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, doros_B1_5positions, n_fit=5, od_ls = True )\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 linfit15\":\n",
    "            analysis_B1_5positions, od_std_b1 = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, doros_B1_5positions, n_fit=15)\n",
    "        elif params[\"b1_strategy\"]==\"doros, b1 linfit15, od_ls\":\n",
    "            analysis_B1_5positions, od_std_b1 = linfit_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, doros_B1_5positions, n_fit=15, od_ls = True )\n",
    "        else:\n",
    "            raise Exception(\"Bb1 strategy unknown \"+params[\"b1_strategy\"]) \n",
    "\n",
    "    ## fit linear function\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    a0 = (computed_head_on_bs_position[-1]-computed_head_on_bs_position[0])/(analysis_B1_5positions[-1]-analysis_B1_5positions[0])\n",
    "    b0 = 0\n",
    "    popt_lin, pcov_lin = curve_fit(lin, analysis_B1_5positions, computed_head_on_bs_position, sigma=computed_head_on_bs_position_unc, p0=[a0, b0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    if not (np.isfinite(a) and np.isfinite(b)):\n",
    "        print(a, b)\n",
    "        print([\n",
    "            analysis_B1_5positions,\n",
    "            computed_head_on_bs_position,\n",
    "        ])\n",
    "        raise Exception(\"reuslt is not finite\")\n",
    "        \n",
    "    return [\n",
    "                a, pcov_lin[0,0]**0.5, \n",
    "                od_std_b1, od_std_sep, \n",
    "                od_std_b1_full_naiive, od_std_b2_full_naiive, \n",
    "                od_std_b1_full_naiive2, od_std_b2_full_naiive2, \n",
    "                od_std_b1_full_fit, od_std_b2_full_fit\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(argv):\n",
    "\n",
    "    params, N, plot = argv\n",
    "\n",
    "    OD_distribution = params[\"OD_distribution\"]\n",
    "\n",
    "    settings_txt = \"\\n\".join([\n",
    "        \"Settings:\",\n",
    "        \"position handling strategy:\\n  \" + \"\\n  \".join([\n",
    "            params[\"sep_strategy\"],\n",
    "            params[\"miniscan_b1_strategy\"],\n",
    "            params[\"b1_strategy\"],\n",
    "        ]),\n",
    "        \"head-on determination method: {}\".format(params[\"headon_determination_method\"]),\n",
    "        \"Nominal LS B1: {}\".format(params[\"Nominal_LS_B1\"]),\n",
    "        \"Nominal LS B2: {}\".format(params[\"Nominal_LS_B2\"]),\n",
    "        \"Doros LS B1: {}\".format(params[\"Doros_LS_B1\"]),\n",
    "        \"Doros LS B2: {}\".format(params[\"Doros_LS_B2\"]),\n",
    "        # \"Arc_LS_B1: {}\".format(params[\"Arc_LS_B1\"]),\n",
    "        # \"Arc_LS_B2: {}\".format(params[\"Arc_LS_B2\"]),\n",
    "        \"Sigma B1: {} um\".format(params[\"Sigma_B1\"]),\n",
    "        \"Sigma B2: {} um\".format(params[\"Sigma_B2\"]),\n",
    "        \"nominal step size B1: {} um\".format(params[\"nominal_step_size_B1\"]),\n",
    "        \"nominal step size B2: {} um\".format(params[\"nominal_step_size_B2\"]),\n",
    "        \"OD distribution: {}\".format(OD_distribution),\n",
    "        \"Markov Chain OD: {}\".format(params[\"cumulative_OD\"]),\n",
    "        \"Doros noise_sigma: {} um\".format(params[\"Doros_noise_sigma\"]),\n",
    "        \"rate runcertainty at head on: {}%\".format(params[\"rate_runcertainty_at_head_on\"]*100),\n",
    "        \"randomize rates: {}\".format(params[\"randomize_rates\"]),\n",
    "        \"beamspot position uncertainty: {}\".format(params[\"beamspot_position_uncertainty\"]),\n",
    "        \"randomize beamspot position: {}\".format(params[\"randomize_beamspot_position\"]),\n",
    "    ])\n",
    "\n",
    "   \n",
    "    ls_results = []\n",
    "    ls_result_errs = []\n",
    "    ls_result_od_b1_errs = []\n",
    "    ls_result_od_sep_errs = []\n",
    "    ls_result_od_std_b1_full_naiive = []\n",
    "    ls_result_od_std_b2_full_naiive = []\n",
    "    ls_result_od_std_b1_full_naiive2 = []\n",
    "    ls_result_od_std_b2_full_naiive2 = []\n",
    "    ls_result_od_std_b1_full_fit = []\n",
    "    ls_result_od_std_b2_full_fit = []\n",
    "    for i in range(N):\n",
    "\n",
    "        np.random.seed(i)\n",
    "\n",
    "        if OD_distribution[0] == \"Normal\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":np.random.normal(size=15)*sigma_OD,\n",
    "                    \"OD_B2\":np.random.normal(size=15)*sigma_OD,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalSum\":\n",
    "            p_OD = OD_distribution[1]\n",
    "            sigma1_OD = OD_distribution[2]\n",
    "            sigma2_OD = OD_distribution[3]\n",
    "            mask  = np.random.random(size=15)<p_OD\n",
    "            od_b1 = np.random.normal(size=15)*sigma1_OD * mask  + np.random.normal(size=15)*sigma2_OD * (1-mask)\n",
    "            mask  = np.random.random(size=15)<p_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma1_OD * mask  + np.random.normal(size=15)*sigma2_OD * (1-mask)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"AsymNormal\":\n",
    "            sigma1_OD = OD_distribution[1]\n",
    "            sigma2_OD = OD_distribution[2]\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":np.random.normal(size=15)*sigma1_OD,\n",
    "                    \"OD_B2\":np.random.normal(size=15)*sigma2_OD,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB1kick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b1[int(np.random.random()*15)] = OD_distribution[2]\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB1skick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b1[int(np.random.random()*15)] = OD_distribution[2] * (-1)**int(np.random.random()*2)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB2kick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2[int(np.random.random()*15)] = OD_distribution[2]\n",
    "            # print(od_b1)\n",
    "            # print(od_b2)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"NormalB2skick\":\n",
    "            sigma_OD = OD_distribution[1]\n",
    "            od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "            od_b2[int(np.random.random()*15)] = OD_distribution[2] * (-1)**int(np.random.random()*2)\n",
    "            # print(od_b1)\n",
    "            # print(od_b2)\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        elif OD_distribution[0] == \"CauchyLim\":\n",
    "            gamma_OD = OD_distribution[1]\n",
    "            lim = OD_distribution[2]\n",
    "\n",
    "            od_b1 = np.random.standard_cauchy(size=15)*gamma_OD\n",
    "            od_b1 = np.clip( od_b1, a_min=-lim, a_max=lim)\n",
    "            od_b2 = np.random.standard_cauchy(size=15)*gamma_OD\n",
    "            od_b2 = np.clip( od_b2, a_min=-lim, a_max=lim)\n",
    "\n",
    "            params.update(\n",
    "                {\n",
    "                    \"OD_B1\":od_b1,\n",
    "                    \"OD_B2\":od_b2,\n",
    "                })\n",
    "        else:\n",
    "            raise ValueError(\"Unknown OD model.\")\n",
    "\n",
    "        try:\n",
    "            ls, lse, \\\n",
    "            od_std_b1, od_std_sep, \\\n",
    "            od_std_b1_full_naiive, od_std_b2_full_naiive, \\\n",
    "            od_std_b1_full_naiive2, od_std_b2_full_naiive2, \\\n",
    "            od_std_b1_full_fit, od_std_b2_full_fit = lsc(params)\n",
    "            ls_results.append(ls)\n",
    "            ls_result_errs.append(lse)\n",
    "            ls_result_od_b1_errs.append(od_std_b1)\n",
    "            ls_result_od_sep_errs.append(od_std_sep)\n",
    "            ls_result_od_std_b1_full_naiive.append(od_std_b1_full_naiive)\n",
    "            ls_result_od_std_b2_full_naiive.append(od_std_b2_full_naiive)\n",
    "            ls_result_od_std_b1_full_naiive2.append(od_std_b1_full_naiive2)\n",
    "            ls_result_od_std_b2_full_naiive2.append(od_std_b2_full_naiive2)\n",
    "            ls_result_od_std_b1_full_fit.append(od_std_b1_full_fit)\n",
    "            ls_result_od_std_b2_full_fit.append(od_std_b2_full_fit)\n",
    "        except Exception as e:\n",
    "            print(\"Error escaped worker function.\")\n",
    "            print(\"Error:\")\n",
    "            print(e)\n",
    "            print(\"Args:\")\n",
    "            print(argv)\n",
    "            print(\"Traceback:\")\n",
    "            print(traceback.print_exc())\n",
    "            \n",
    "\n",
    "            with open(\"err.txt\", \"w\") as f:\n",
    "                f.write(\"{}\\n{}\\n{}\".format(argv, traceback.print_exc(), e))\n",
    "\n",
    "            raise RuntimeError(\"Error in worker function.\")\n",
    "\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        fig.patch.set_facecolor('white')\n",
    "        gs = gridspec.GridSpec(2,2)\n",
    "        # gs.update(hspace=0.1)\n",
    "\n",
    "        ax0  = fig.add_subplot(gs[0,0])\n",
    "        ax0.set_xlabel(\"LS\", fontsize=16)\n",
    "        ax1 = fig.add_subplot(gs[1,0])\n",
    "        ax1.set_xlabel(\"LS unc $\\\\times$ 100\", fontsize=16)\n",
    "        for ax in [ax0, ax1]:\n",
    "            ax.grid(True)\n",
    "            ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "            ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[:,1])   \n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax2.spines[axis].set_linewidth(0.0)\n",
    "        ax2.tick_params(\n",
    "                axis='both',          \n",
    "                which='both',     \n",
    "                bottom=False,      \n",
    "                top=False, \n",
    "                left=False,      \n",
    "                right=False,         \n",
    "                labelbottom=False,\n",
    "                labelleft=False)\n",
    "\n",
    "        \n",
    "\n",
    "        ax0.hist(ls_results, 50, density=False, facecolor='b', alpha=0.75)\n",
    "        ax1.hist(ls_result_errs*100, 50, density=False, facecolor='g', alpha=0.75)\n",
    "        # ax0.hist((np.array(ls_results)-1)*100, 50, density=False, facecolor='b', alpha=0.75)\n",
    "        # ax1.hist((np.array(ls_results)-1)*1000, 50, density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "\n",
    "        ax0.set_ylim(0, ax0.get_ylim()[1]*1.15)\n",
    "        ax0.text(0.02, 0.97, \"Mean: {:0.4f}$\\\\pm${:0.4f}\\nStd:{:0.4f}\".format(np.mean(ls_results), np.std(ls_results, ddof=1)/N**0.5, np.std(ls_results, ddof=1)),\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax0.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='bold',\n",
    "                        fontsize=14)\n",
    "\n",
    "        ax1.set_ylim(0, ax1.get_ylim()[1]*1.15)\n",
    "        ax1.text(0.02, 0.97, \"Mean: {:0.4f}$\\\\pm${:0.4f}\\nStd:{:0.4f}\".format(np.mean(ls_result_errs), np.std(ls_result_errs, ddof=1)/N**0.5,  np.std(ls_result_errs, ddof=1)),\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax1.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='bold',\n",
    "                        fontsize=14)\n",
    "\n",
    "        ax2.text(0.02, 0.97, settings_txt,\n",
    "                        horizontalalignment='left',\n",
    "                        verticalalignment='top',\n",
    "                        transform=ax2.transAxes,\n",
    "                        fontname='sans-serif',\n",
    "                        fontweight='normal',\n",
    "                        fontsize=14)\n",
    "\n",
    "        fig.savefig(\"OD_{}_cumulative_{}_strategy_{}_{}.png\".format(\n",
    "            OD_distribution, \n",
    "            cumulative_OD, \n",
    "            params[\"pos_strategy\"],\n",
    "            params[\"headon_determination_method\"]\n",
    "            ))\n",
    "        plt.close(fig)\n",
    "\n",
    "    return [\n",
    "            params[\"cumulative_OD\"], \n",
    "            params[\"OD_distribution\"], \n",
    "            params[\"pos_strategy\"], \n",
    "            params[\"headon_determination_method\"], \n",
    "            #\n",
    "            ls_results, ls_result_errs, \n",
    "            ls_result_od_b1_errs, ls_result_od_sep_errs, \n",
    "            ls_result_od_std_b1_full_naiive, ls_result_od_std_b2_full_naiive,\n",
    "            ls_result_od_std_b1_full_naiive2, ls_result_od_std_b2_full_naiive2,\n",
    "            ls_result_od_std_b1_full_fit, ls_result_od_std_b2_full_fit\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    params = {\n",
    "        \"Nominal_LS_B1\":0.9975,\n",
    "        \"Nominal_LS_B2\":0.995,\n",
    "        \"Doros_LS_B1\":1.0025,\n",
    "        \"Doros_LS_B2\":1.005,\n",
    "        \"Arc_LS_B1\":1.005,\n",
    "        \"Arc_LS_B2\":1.01,\n",
    "        \"Sigma_B1\":90, #micron\n",
    "        \"Sigma_B2\":90, #micron\n",
    "        \"nominal_step_size_B1\": 130, #micron\n",
    "        \"nominal_step_size_B2\": 130, #micron\n",
    "        \"Doros_noise_sigma\":0.25, # micron\n",
    "        \"Arc_noise_sigma\":0, # micron\n",
    "        \"rate_runcertainty_at_head_on\":0.005, #relative\n",
    "        \"randomize_rates\":True,\n",
    "        \"beamspot_position_uncertainty\":0.25, #micron\n",
    "        \"randomize_beamspot_position\":True,\n",
    "        ##\n",
    "        \"cumulative_OD\":True,\n",
    "        \"OD_distribution\":(\"Normal\",2),\n",
    "        \"headon_determination_method\":\"CMS\",\n",
    "        #\n",
    "        \"b1_strategy\":\"doros, b1 linfit\",\n",
    "        \"miniscan_b1_strategy\":\"fit\",\n",
    "        \"sep_strategy\":\"doros\",\n",
    "        \"pos_strategy\":\"whatever\",\n",
    "        #\n",
    "    }\n",
    "\n",
    "    _ = worker([params, 10, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "make_plots = True\n",
    "parallel_execution = True\n",
    "\n",
    "params = {\n",
    "    \"Nominal_LS_B1\":0.9975,\n",
    "    \"Nominal_LS_B2\":0.995,\n",
    "    \"Doros_LS_B1\":1.0025,\n",
    "    \"Doros_LS_B2\":1.005,\n",
    "    \"Arc_LS_B1\":1.005,\n",
    "    \"Arc_LS_B2\":1.01,\n",
    "    \"Sigma_B1\":90, #micron\n",
    "    \"Sigma_B2\":90, #micron\n",
    "    \"nominal_step_size_B1\": 130, #micron\n",
    "    \"nominal_step_size_B2\": 130, #micron\n",
    "    \"Doros_noise_sigma\":0.25, # micron, statistical fluctuation on top of true value\n",
    "    \"Arc_noise_sigma\":0, # micron\n",
    "    \"rate_runcertainty_at_head_on\":0.005, #relative\n",
    "    \"randomize_rates\":True,\n",
    "    \"beamspot_position_uncertainty\":0.25, #micron, looks like 0.15 um in Mahmoud's fits btw\n",
    "    \"randomize_beamspot_position\":True,\n",
    "}\n",
    "\n",
    "pos_strategies = { # b1_strategy, miniscan_b1_strategy, sep_strategy\n",
    "    \"nominal, middle point\":(\"nominal\", \"middle\", \"nominal\"),\n",
    "    #\n",
    "    \"doros, middle point\":  (\"doros\", \"middle\", \"doros\"),\n",
    "    \"doros, avg point\":     (\"doros\", \"avg\", \"doros\"),\n",
    "    \"doros, fit point\":     (\"doros\", \"fit\", \"doros\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, avg point\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, avg point\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize2\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, avg point\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier2\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, avg point\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, avg point\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, avg point\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier2\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize outlier1_0.35, sep stepsize10, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, sep stepsize10 outlier4, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, sep stepsize10 outlier2, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros, sep stepsize10 outlier2\"),\n",
    "    \"doros, b1 stepsize outlier2_0.35, sep stepsize10, avg point\":(\"doros, b1 stepsize outlier2_0.35\", \"avg\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier2_0.35, sep stepsize10 outlier4, avg point\":(\"doros, b1 stepsize outlier2_0.35\", \"avg\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier2_0.35, sep stepsize10 outlier2, avg point\":(\"doros, b1 stepsize outlier2_0.35\", \"avg\", \"doros, sep stepsize10 outlier2\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4_0.50, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier4_0.50\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2_0.50, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier2_0.50\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4_0.50, avg point\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier4_0.50\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2_0.50, avg point\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier2_0.50\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize outlier1_0.35, sep stepsize10 outlier4_0.50, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros, sep stepsize10 outlier4_0.50\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, sep stepsize10 outlier2_0.50, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros, sep stepsize10 outlier2_0.50\"),\n",
    "    \"doros, b1 stepsize outlier2_0.35, sep stepsize10 outlier4_0.50, avg point\":(\"doros, b1 stepsize outlier2_0.35\", \"avg\", \"doros, sep stepsize10 outlier4_0.50\"),\n",
    "    \"doros, b1 stepsize outlier2_0.35, sep stepsize10 outlier2_0.50, avg point\":(\"doros, b1 stepsize outlier2_0.35\", \"avg\", \"doros, sep stepsize10 outlier2_0.50\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, middle point\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, middle point\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize2\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, middle point\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, middle point\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, middle point\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, middle point\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10 outlier2\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, middle point\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, middle point\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, middle point\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10 outlier2\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, fit point\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, fit point\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize2\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, fit point\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, fit point\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, fit point\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, fit point\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10 outlier2\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, fit point\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, fit point\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10 outlier4\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, fit point\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10 outlier2\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, avg point, od_ls\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, avg point, od_ls\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize2, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, avg point, od_ls\":(\"doros, b1 stepsize\", \"avg\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, avg point, od_ls\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, avg point, od_ls\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, avg point, od_ls\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, avg point, od_ls\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, avg point, od_ls\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, avg point, od_ls\":(\"doros, b1 stepsize outlier2\", \"avg\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, middle point, od_ls\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, middle point, od_ls\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize2, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, middle point, od_ls\":(\"doros, b1 stepsize\", \"middle\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, middle point, od_ls\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, middle point, od_ls\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, middle point, od_ls\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, middle point, od_ls\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, middle point, od_ls\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, middle point, od_ls\":(\"doros, b1 stepsize outlier2\", \"middle\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, sep stepsize10, fit point, od_ls\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize2, fit point, od_ls\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize2, od_ls\"),\n",
    "    \"doros, b1 stepsize, sep stepsize10 outlier4, fit point, od_ls\":(\"doros, b1 stepsize\", \"fit\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10, fit point, od_ls\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, fit point, od_ls\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier1, sep stepsize10 outlier2, fit point, od_ls\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10, fit point, od_ls\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, fit point, od_ls\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10 outlier4, od_ls\"),\n",
    "    \"doros, b1 stepsize outlier2, sep stepsize10 outlier2, fit point, od_ls\":(\"doros, b1 stepsize outlier2\", \"fit\", \"doros, sep stepsize10 outlier2, od_ls\"),\n",
    "    #\n",
    "    \"doros, b1 stepsize, avg point\":(\"doros, b1 stepsize\", \"avg\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1, avg point\":(\"doros, b1 stepsize outlier1\", \"avg\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, avg point\":(\"doros, b1 stepsize outlier1_0.35\", \"avg\", \"doros\"),\n",
    "    \"doros, b1 stepsize, middle point\":(\"doros, b1 stepsize\", \"middle\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1, middle point\":(\"doros, b1 stepsize outlier1\", \"middle\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, middle point\":(\"doros, b1 stepsize outlier1_0.35\", \"middle\", \"doros\"),\n",
    "    \"doros, b1 stepsize, fit point\":(\"doros, b1 stepsize\", \"fit\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1, fit point\":(\"doros, b1 stepsize outlier1\", \"fit\", \"doros\"),\n",
    "    \"doros, b1 stepsize outlier1_0.35, fit point\":(\"doros, b1 stepsize outlier1_0.35\", \"fit\", \"doros\"),\n",
    "    #\n",
    "    \"doros, rel. ls based unc 0.25%, avg point\":(\"doros, rel. ls based unc 0.25%\", \"avg\", \"doros, rel. ls based unc 0.25%\"),\n",
    "    \"doros, rel. ls based unc 0.25%, middle point\":(\"doros, rel. ls based unc 0.25%\", \"middle\", \"doros, rel. ls based unc 0.25%\"),\n",
    "    \"doros, rel. ls based unc 0.25%, fit point\":(\"doros, rel. ls based unc 0.25%\", \"fit\", \"doros, rel. ls based unc 0.25%\"),\n",
    "    \"doros, rel. ls based unc 0.5%, avg point\":(\"doros, rel. ls based unc 0.5%\", \"avg\", \"doros, rel. ls based unc 0.5%\"),\n",
    "    \"doros, rel. ls based unc 0.5%, middle point\":(\"doros, rel. ls based unc 0.5%\", \"middle\", \"doros, rel. ls based unc 0.5%\"),\n",
    "    \"doros, rel. ls based unc 0.5%, fit point\":(\"doros, rel. ls based unc 0.5%\", \"fit\", \"doros, rel. ls based unc 0.5%\"),\n",
    "    \"doros, rel. ls based unc 1%, avg point\":(\"doros, rel. ls based unc 1%\", \"avg\", \"doros, rel. ls based unc 1%\"),\n",
    "    \"doros, rel. ls based unc 1%, middle point\":(\"doros, rel. ls based unc 1%\", \"middle\", \"doros, rel. ls based unc 1%\"),\n",
    "    \"doros, rel. ls based unc 1%, fit point\":(\"doros, rel. ls based unc 1%\", \"fit\", \"doros, rel. ls based unc 1%\"),\n",
    "    #\n",
    "    \"doros, b1 linfit5, sep linfit, avg point\":(\"doros, b1 linfit5\", \"avg\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit5, sep linfit, avg point, od_ls\":(\"doros, b1 linfit5, od_ls\", \"avg\", \"doros, sep linfit, od_ls\"),\n",
    "    \"doros, b1 linfit5, sep linfit, middle point\":(\"doros, b1 linfit5\", \"middle\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit5, sep linfit, middle point, od_ls\":(\"doros, b1 linfit5, od_ls\", \"middle\", \"doros, sep linfit, od_ls\"),\n",
    "    \"doros, b1 linfit5, sep linfit, fit point\":(\"doros, b1 linfit5\", \"fit\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit5, sep linfit, fit point, od_ls\":(\"doros, b1 linfit5, od_ls\", \"fit\", \"doros, sep linfit, od_ls\"),\n",
    "    #\n",
    "    \"doros, b1 linfit15, sep linfit, avg point\":(\"doros, b1 linfit15\", \"avg\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit15, sep linfit, avg point, od_ls\":(\"doros, b1 linfit15, od_ls\", \"avg\", \"doros, sep linfit, od_ls\"),\n",
    "    \"doros, b1 linfit15, sep linfit, middle point\":(\"doros, b1 linfit15\", \"middle\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit15, sep linfit, middle point, od_ls\":(\"doros, b1 linfit15, od_ls\", \"middle\", \"doros, sep linfit, od_ls\"),\n",
    "    \"doros, b1 linfit15, sep linfit, fit point\":(\"doros, b1 linfit15\", \"fit\", \"doros, sep linfit\"),\n",
    "    \"doros, b1 linfit15, sep linfit, fit point, od_ls\":(\"doros, b1 linfit15, od_ls\", \"fit\", \"doros, sep linfit, od_ls\"),\n",
    "}\n",
    "\n",
    "# Standard normal distribution 84.1% percentile --> +1 sigma\n",
    "# Standard Cauchy distribution 84.1% percentile --> ~ 2\n",
    "\n",
    "jobs = []\n",
    "cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results = {}\n",
    "\n",
    "for cumulative_OD in [True]: #, False]:\n",
    "    cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[cumulative_OD] = {}\n",
    "    for OD_distribution in [\n",
    "                                (\"Normal\", 0), (\"Normal\", 0.25), (\"Normal\", 0.5), (\"Normal\", 1), \n",
    "                                (\"Normal\", 2), (\"Normal\", 4), (\"Normal\", 8), (\"Normal\", 16),\n",
    "                                (\"AsymNormal\", 1, 4), (\"AsymNormal\", 1, 8),\n",
    "                                (\"AsymNormal\", 4, 1), (\"AsymNormal\", 8, 1),\n",
    "                                (\"NormalB1kick\", 2, 8), (\"NormalB1skick\", 2, 8), \n",
    "                                (\"NormalB2kick\", 2, 8), (\"NormalB2skick\", 2, 8),\n",
    "                                (\"NormalSum\", 0.9, 1, 4), \n",
    "                                (\"NormalSum\", 0.9, 1, 8), \n",
    "                                (\"NormalSum\", 0.9, 1, 12), \n",
    "                                (\"NormalSum\", 0.9, 2, 8), \n",
    "                                (\"CauchyLim\", 1, 20),  \n",
    "                                #\n",
    "                                # (\"Normal\", 8)\n",
    "                            ]:\n",
    "        cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[cumulative_OD][OD_distribution] = {}\n",
    "    \n",
    "        for pos_strategy_name, pos_strategy in pos_strategies.items():\n",
    "            cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[cumulative_OD][OD_distribution][pos_strategy_name] = {}\n",
    "            \n",
    "            b1_strategy, miniscan_b1_strategy, sep_strategy = pos_strategy\n",
    "            \n",
    "            if not miniscan_b1_strategy == \"fit\":\n",
    "                headon_determination_methods = [\"ATLAS\", \"CMS\"]\n",
    "            else:\n",
    "                headon_determination_methods = [\"CMS\"]\n",
    "            \n",
    "            for headon_determination_method in headon_determination_methods:\n",
    "                cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results\n",
    "\n",
    "                p_temp = dict(params)\n",
    "                p_temp[\"cumulative_OD\"]                 = cumulative_OD\n",
    "                p_temp[\"OD_distribution\"]               = OD_distribution\n",
    "                p_temp[\"headon_determination_method\"]   = headon_determination_method\n",
    "                #\n",
    "                p_temp[\"b1_strategy\"]                   = b1_strategy\n",
    "                p_temp[\"miniscan_b1_strategy\"]          = miniscan_b1_strategy\n",
    "                p_temp[\"sep_strategy\"]                  = sep_strategy\n",
    "                p_temp[\"pos_strategy\"]                  = pos_strategy_name\n",
    "\n",
    "                if not parallel_execution:\n",
    "                    result = worker([p_temp, N, make_plots])\n",
    "                    \n",
    "                    cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[cumulative_OD][OD_distribution][pos_strategy_name][headon_determination_method] = \\\n",
    "                    result[4:]\n",
    "                else:\n",
    "                    jobs.append([p_temp, N, make_plots])   \n",
    "\n",
    "\n",
    "if parallel_execution:\n",
    "\n",
    "    threads_available = int(os.popen('grep -c cores /proc/cpuinfo').read())#/2\n",
    "    concurrent_jobs   = threads_available - 2\n",
    "\n",
    "    start = time.time()\n",
    "    pool = multiprocessing.Pool(processes=concurrent_jobs)\n",
    "    print(concurrent_jobs, \"pools started\")\n",
    "\n",
    "    try:\n",
    "        for i, result in enumerate(pool.imap_unordered(worker, jobs), 1):\n",
    "\n",
    "            cumulative_OD   = result[0]\n",
    "            OD_distribution = result[1]\n",
    "            pos_strategy    = result[2]\n",
    "            headon_determination_method = result[3]\n",
    "            cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[cumulative_OD][OD_distribution][pos_strategy][headon_determination_method] = result[4:]\n",
    "\n",
    "            if i>10:\n",
    "                eta_min = int(((len(jobs)-i)*(time.time()-start)/i)/60)\n",
    "                sys.stdout.write('\\rdone {0:%}, ETA: {1:d} mins  '.format(float(i)/len(jobs), eta_min))\n",
    "            elif i==0:\n",
    "                sys.stdout.write('done {0:%}'.format(float(i)/len(jobs)))\n",
    "            else:\n",
    "                sys.stdout.write('\\rdone {0:0.2%}'.format(float(i)/len(jobs)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print( 'Got ^C while pool mapping, terminating the pool' )\n",
    "        pool.terminate()\n",
    "        print( 'pool is terminated' )\n",
    "    except Exception as e:\n",
    "        print( 'Caught exception from one of the workers', e )\n",
    "        pool.terminate()\n",
    "        print( 'pool is terminated' )\n",
    "    finally:\n",
    "        pool.close()\n",
    "    print(\"\\n\", (time.time()-start), \"sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sim_result.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results, f)\n",
    "\n",
    "for k in cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True].keys():\n",
    "    with open(\"sim_result_10k_2_{}.pkl\".format(k), \"wb\") as f:\n",
    "        pickle.dump(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][k], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [\n",
    "    (\"Normal\", 0), (\"Normal\", 2), (\"Normal\", 4), (\"Normal\", 8), \n",
    "    (\"NormalB1kick\", 2, 8), (\"NormalB2kick\", 2, 8), \n",
    "    (\"NormalSum\", 0.9, 2, 8), \n",
    "    (\"CauchyLim\", 1, 20),  \n",
    "]\n",
    "lines = [\n",
    "    'doros, avg point',\n",
    "    'doros, middle point',\n",
    "    'doros, fit point',\n",
    "]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax  = fig.add_subplot(121)\n",
    "ax.set_ylabel(\"Bias [%]\", fontsize=16)\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "x = range(len(x_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "for headon_determination_method in [\"CMS\", \"ATLAS\"]:\n",
    "    for line_name in lines:\n",
    "        if not headon_determination_method in cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][x_labels[0]][line_name]:\n",
    "            continue\n",
    "        y  = [ np.mean(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][line_name][headon_determination_method][0]) for odd in x_labels ]\n",
    "        y  = 100*(np.array(y)-1.0025)\n",
    "        p = ax.plot(x, y, label=line_name + \", head-on: \" + headon_determination_method)\n",
    "        \n",
    "        if len(lines)<5:\n",
    "            N  = [ len(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][line_name][headon_determination_method][0]) for odd in x_labels ]\n",
    "            ye = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][line_name][headon_determination_method][0], ddof=1) for odd in x_labels ]\n",
    "            ye = 100*np.array(ye)\n",
    "            ax.fill_between(x, y-ye/np.sqrt(N), y+ye/np.sqrt(N), color=p[0].get_color(), alpha=0.3)\n",
    "\n",
    "a, b = ax.get_ylim()\n",
    "ax.set_ylim(a, a+(b-a)*(1+len(lines)/15) )\n",
    "\n",
    "ax.legend(fontsize=16)\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "\n",
    "ax  = fig.add_subplot(122)\n",
    "ax.set_ylabel(\"Spread of bias [%]\", fontsize=16)\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "x = range(len(x_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "for headon_determination_method in [\"CMS\", \"ATLAS\"]:\n",
    "    for line_name in lines:\n",
    "        if not headon_determination_method in cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][x_labels[0]][line_name]:\n",
    "            continue\n",
    "        ye = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][line_name][headon_determination_method][0]) for odd in x_labels ]\n",
    "        ax.plot(x, 100*np.array(ye), label=line_name)\n",
    "       \n",
    "\n",
    "# ax.legend(fontsize=16)\n",
    "\n",
    "if save_figures:\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"BPM_lsc_methods.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][(\"Normal\", 8)]['doros, fit point'][\"CMS\"][0]\n",
    "print(np.mean(x))\n",
    "print(np.std(x, ddof=1))\n",
    "print(np.min(x)-np.mean(x))\n",
    "print(np.max(x)-np.mean(x))\n",
    "imin = np.argmin(x)\n",
    "imax = np.argmax(x)\n",
    "x2 = np.concatenate((x[:imin], x[imin+1:]))\n",
    "x2 = np.concatenate((x2[:imax], x2[imax+1:]))\n",
    "print(\"imin\", imin)\n",
    "print(\"==============\")\n",
    "print(np.mean(x2))\n",
    "print(np.std(x2, ddof=1))\n",
    "print(np.min(x2)-np.mean(x2))\n",
    "print(np.max(x2)-np.mean(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headon_determination_method = \"CMS\"\n",
    "spread_ratio = False\n",
    "postfix = \"\"\n",
    "\n",
    "x_labels = [\n",
    "    (\"Normal\", 0), (\"Normal\", 2), (\"Normal\", 4), (\"Normal\", 8), \n",
    "    (\"NormalB1kick\", 2, 8), (\"NormalB2kick\", 2, 8), \n",
    "    (\"NormalB1skick\", 2, 8), (\"NormalB2skick\", 2, 8), \n",
    "    (\"NormalSum\", 0.9, 2, 8), \n",
    "    (\"CauchyLim\", 1, 20),  \n",
    "]\n",
    "\n",
    "x_labels = [\n",
    "    (\"Normal\", 0), (\"Normal\", 0.25), (\"Normal\", 0.5), (\"Normal\", 1), (\"Normal\", 2), (\"Normal\", 4),\n",
    "    (\"AsymNormal\", 1, 4),\n",
    "    (\"AsymNormal\", 4, 1),\n",
    "    (\"NormalSum\", 0.9, 2, 8), \n",
    "    (\"CauchyLim\", 1, 20), \n",
    "]\n",
    "postfix = \"_x2\"\n",
    "\n",
    "figures =[\n",
    "    [\n",
    "        'nominal, middle point',\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, fit point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, avg point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, middle point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, fit point\",\n",
    "        \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, avg point\",\n",
    "        \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, middle point\",\n",
    "        \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, fit point\",\n",
    "    ],\n",
    "    [\n",
    "        ['nominal, middle point', \"CMS\"],\n",
    "        ['nominal, middle point', \"ATLAS\"],\n",
    "        [\"doros, b1 stepsize, sep stepsize10, avg point\", \"CMS\"],\n",
    "        [\"doros, b1 stepsize, sep stepsize10, avg point\", \"ATLAS\"],\n",
    "        [\"doros, b1 stepsize, sep stepsize10, middle point\", \"CMS\"],\n",
    "        [\"doros, b1 stepsize, sep stepsize10, middle point\", \"ATLAS\"],\n",
    "        [\"doros, b1 stepsize, sep stepsize10, fit point\", \"CMS\"],\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, fit point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point, od_ls\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point, od_ls\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, fit point, od_ls\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, avg point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, middle point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, fit point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, avg point, od_ls\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, middle point, od_ls\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10 outlier4, fit point, od_ls\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point\",\n",
    "        #\n",
    "        \"doros, b1 stepsize, avg point\",\n",
    "        \"doros, b1 stepsize outlier1, avg point\",\n",
    "        #\n",
    "        \"doros, b1 stepsize, middle point\",\n",
    "        \"doros, b1 stepsize outlier1, middle point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, avg point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10 outlier4, avg point\",\n",
    "        \"doros, b1 stepsize, avg point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize outlier1_0.35, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize outlier1_0.35, sep stepsize10 outlier4, avg point\",\n",
    "        \"doros, b1 stepsize outlier1_0.35, avg point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize outlier1, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize outlier1_0.35, sep stepsize10, avg point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, fit point\",\n",
    "        #\n",
    "        \"doros, b1 linfit5, sep linfit, avg point\",\n",
    "        \"doros, b1 linfit5, sep linfit, middle point\",\n",
    "        \"doros, b1 linfit5, sep linfit, fit point\",\n",
    "        #\n",
    "        \"doros, b1 linfit15, sep linfit, avg point\",\n",
    "        \"doros, b1 linfit15, sep linfit, middle point\",\n",
    "        \"doros, b1 linfit15, sep linfit, fit point\",\n",
    "    ],\n",
    "    [\n",
    "        \"doros, b1 stepsize, sep stepsize10, avg point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, middle point\",\n",
    "        \"doros, b1 stepsize, sep stepsize10, fit point\",\n",
    "        #\n",
    "        \"doros, rel. ls based unc 0.25%, avg point\",\n",
    "        \"doros, rel. ls based unc 0.25%, middle point\",\n",
    "        \"doros, rel. ls based unc 0.25%, fit point\",\n",
    "        \"doros, rel. ls based unc 0.5%, avg point\",\n",
    "        \"doros, rel. ls based unc 0.5%, middle point\",\n",
    "        \"doros, rel. ls based unc 0.5%, fit point\",\n",
    "        \"doros, rel. ls based unc 1%, avg point\",\n",
    "        \"doros, rel. ls based unc 1%, middle point\",\n",
    "        \"doros, rel. ls based unc 1%, fit point\",\n",
    "    ]\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,lines in enumerate(figures):\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    ax  = fig.add_subplot(121)\n",
    "    ax.set_ylabel(\"Bias [%]\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "        y  = [ np.mean(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0]) for odd in x_labels ]\n",
    "        y  = 100*(np.array(y)-0.9975)\n",
    "        p = ax.plot(x, y, label=line_name)\n",
    "        \n",
    "        if len(lines)<5:\n",
    "            N  = [ len(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0]) for odd in x_labels ]\n",
    "            ye = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0], ddof=1) for odd in x_labels ]\n",
    "            ye = 100*np.array(ye)\n",
    "            ax.fill_between(x, y-ye/np.sqrt(N), y+ye/np.sqrt(N), color=p[0].get_color(), alpha=0.3)\n",
    "\n",
    "    a, b = ax.get_ylim()\n",
    "    ax.set_ylim(a, a+(b-a)*(1+len(lines)/15) )\n",
    "\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "\n",
    "    ######################\n",
    "\n",
    "\n",
    "    ax  = fig.add_subplot(122)\n",
    "    if spread_ratio:\n",
    "        ax.set_ylabel(\"Spread <method> / Spread <method 1> - 1\", fontsize=16)\n",
    "    else:\n",
    "        ax.set_ylabel(\"Spread of bias [%]\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    if spread_ratio:\n",
    "\n",
    "        line_name = lines[0]\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "        ye1 = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0], ddof=1) for odd in x_labels ]\n",
    "    \n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "        ye = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0], ddof=1) for odd in x_labels ]\n",
    "        if spread_ratio:\n",
    "            ye = np.array(ye)/ye1 - 1\n",
    "        else:\n",
    "            ye = 100*np.array(ye)\n",
    "        ax.plot(x, ye, label=line_name)\n",
    "\n",
    "    # ax.legend(fontsize=16)\n",
    "\n",
    "    if save_figures:\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\"Nominal{}_lsc_methods{}.png\".format(i+1, postfix))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,lines in enumerate(figures):\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    ax  = fig.add_subplot(121)\n",
    "    ax.set_ylabel(\"|Bias| [%]\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "        y  = [ np.mean(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0]) for odd in x_labels ]\n",
    "        y  = 100*(np.array(y)-0.9975)\n",
    "        p = ax.plot(x, np.abs(y), label=line_name)\n",
    "        \n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    a, b = ax.get_ylim()\n",
    "    ax.set_ylim(a, a*(b/a)**((1+len(lines)/15)) )\n",
    "\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "\n",
    "    ######################\n",
    "\n",
    "    ax  = fig.add_subplot(122)\n",
    "    ax.set_ylabel(\"Spread <method> / Spread <method 1>\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    line_name = lines[0]\n",
    "    if isinstance(line_name, str):\n",
    "        ln_ = line_name\n",
    "        hdm_ = headon_determination_method\n",
    "    else:\n",
    "        ln_ = line_name[0]\n",
    "        hdm_ = line_name[1]\n",
    "\n",
    "    ye1 = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0], ddof=1) for odd in x_labels ]\n",
    "    \n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "        ye = [ np.std(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0], ddof=1) for odd in x_labels ]\n",
    "        ye = np.array(ye)/ye1\n",
    "        ax.plot(x, ye, label=line_name)\n",
    "\n",
    "    # ax.legend(fontsize=16)\n",
    "\n",
    "    if save_figures:\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\"Nominal{}_lsc_methods_mod{}.png\".format(i+1, postfix))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,lines in enumerate(figures):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    ax  = fig.add_subplot(121)\n",
    "    ax.set_ylabel(\"Fraction of biases above b1 uncertainty [%]\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "\n",
    "        y = []\n",
    "        for odd in x_labels:\n",
    "            ls = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0])\n",
    "            od_unc_b1 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][8])\n",
    "            od_unc_sep = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][9])\n",
    "\n",
    "\n",
    "\n",
    "            d = np.abs(ls - 0.9975) - od_unc_b1 / 130 \n",
    "            y.append( 100 * np.sum(d>0) / len(d) )\n",
    "                \n",
    "        p = ax.plot(x, y, label=line_name)\n",
    "        \n",
    "    \n",
    "    a, b = ax.get_ylim()\n",
    "    ax.set_ylim(a, a+(b-a)*((1+len(lines)/15)) )\n",
    "\n",
    "\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "\n",
    "    ######################\n",
    "\n",
    "    ax  = fig.add_subplot(122)\n",
    "    ax.set_ylabel(\"Fraction of biases above sep uncertainty [%]\", fontsize=16)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "    ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    x = range(len(x_labels))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "    for line_name in lines:\n",
    "\n",
    "        if isinstance(line_name, str):\n",
    "            ln_ = line_name\n",
    "            hdm_ = headon_determination_method\n",
    "        else:\n",
    "            ln_ = line_name[0]\n",
    "            hdm_ = line_name[1]\n",
    "\n",
    "\n",
    "        y = []\n",
    "        for odd in x_labels:\n",
    "            ls = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0])\n",
    "            od_unc_b1 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][8])\n",
    "            od_unc_sep = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][9])\n",
    "\n",
    "            d = np.abs(ls - 0.9975) - od_unc_sep / 130 \n",
    "            y.append( 100 * np.sum(d>0) / len(d) )\n",
    "                \n",
    "        p = ax.plot(x, y, label=line_name)\n",
    "        \n",
    "    \n",
    "\n",
    "    a, b = ax.get_ylim()\n",
    "    ax.set_ylim(a, a+(b-a)*((1+len(lines)/15)) )\n",
    "\n",
    "    ax.legend(fontsize=14)\n",
    "\n",
    "    # ax.legend(fontsize=16)\n",
    "\n",
    "    # if save_figures:\n",
    "    #     fig.tight_layout()\n",
    "    #     fig.savefig(\"Nominal{}_lsc_pc_above_od_unc{}.png\".format(i+1, postfix))\n",
    "    #     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ln_ = \"doros, b1 stepsize, sep stepsize10, avg point\"\n",
    "# ln_ = \"doros, b1 stepsize outlier2, sep stepsize10 outlier4, avg point\"\n",
    "hdm_= \"CMS\"\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax  = fig.add_subplot(121)\n",
    "ax.set_ylabel(\"Fraction of biases above b1 uncertainty [%]\", fontsize=16)\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "x = range(len(x_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(4):\n",
    "    y = []\n",
    "    for odd in x_labels:\n",
    "        ls = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0])\n",
    "        od_unc_b1 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][2*(i+1)])\n",
    "        od_unc_b2 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][2*(i+1)+1])\n",
    "\n",
    "        if i==1:\n",
    "            od_unc_b1/=1.41\n",
    "            od_unc_b2/=1.41\n",
    "\n",
    "        # od_unc_b1 /= 1.2\n",
    "\n",
    "        # d = np.abs(ls - 0.9975) - od_unc_b1 / 130 \n",
    "        d = np.abs(ls - 0.9975) - (np.abs(od_unc_b1**2 - (0.25*1.41)**2))**0.5 / 130 \n",
    "\n",
    "        y.append( 100 * np.sum(d>0) / len(d) )\n",
    "            \n",
    "    p = ax.plot(x, y, label=[\"strategy specific\", \"naiive 1\", \"naiive 2\", \"fit\"][i])\n",
    "    \n",
    "\n",
    "a, b = ax.get_ylim()\n",
    "ax.set_ylim(a, a+(b-a)*((1+len(lines)/15)) )\n",
    "\n",
    "\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "ax  = fig.add_subplot(122)\n",
    "ax.set_ylabel(\"Fraction of biases above b2 (sep) uncertainty [%]\", fontsize=16)\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='y', which='major', direction=\"in\", labelsize=16, pad = 8)\n",
    "ax.tick_params(axis='x', which='major', direction=\"in\", labelsize=16, pad = 12)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "x = range(len(x_labels))\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, rotation=45, ha='right' )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(4):\n",
    "    y = []\n",
    "    for odd in x_labels:\n",
    "        ls = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][0])\n",
    "        od_unc_b1 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][2*(i+1)])\n",
    "        od_unc_b2 = np.array(cumulative_OD2OD_distribution2pos_strategy2ho_det_method2results[True][odd][ln_][hdm_][2*(i+1)+1])\n",
    "\n",
    "        if i==1:\n",
    "            od_unc_b1/=1.41\n",
    "            od_unc_b2/=1.41\n",
    "\n",
    "        d = np.abs(ls - 0.9975) - od_unc_b2 / 130 \n",
    "        y.append( 100 * np.sum(d>0) / len(d) )\n",
    "            \n",
    "    p = ax.plot(x, y, label=[\"strategy specific\", \"naiive 1\", \"naiive 2\", \"fit\"][i])\n",
    "    \n",
    "\n",
    "\n",
    "a, b = ax.get_ylim()\n",
    "ax.set_ylim(a, a+(b-a)*((1+len(lines)/15)) )\n",
    "\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "# ax.legend(fontsize=16)\n",
    "\n",
    "# if save_figures:\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig(\"Nominal{}_lsc_pc_above_od_unc{}.png\".format(i+1, postfix))\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
