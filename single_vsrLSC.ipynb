{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy.optimize import curve_fit\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import iminuit\n",
    "print(\"iminuit version:\", iminuit.__version__)\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS\n",
    "# Computing B1 LS\n",
    "# B1 is stationary\n",
    "# B2 is scanning\n",
    "\n",
    "# definition of LS: BPM_length * LS = true_length\n",
    "\n",
    "params = {\n",
    "    # \"Nominal_LS\":1.05,\n",
    "    \"Nominal_LS_B1\":1.005,\n",
    "    # \"Nominal_LS_B1\":0.995,\n",
    "    # \"Doros_LS_B1\":1.05,\n",
    "    # \"Doros_LS_B1\":1.0,\n",
    "    \"Doros_LS_B1\":0.995,\n",
    "    # \"Arc_LS_B1\":1.05,\n",
    "    \"Arc_LS_B1\":1.0,\n",
    "    # \"Arc_LS_B1\":0.995,\n",
    "    \"Nominal_LS_B2\":1.0,\n",
    "    # \"Nominal_LS_B2\":0.995,\n",
    "    # \"Doros_LS_B2\":1.05,\n",
    "    \"Doros_LS_B2\":0.99,\n",
    "    # \"Doros_LS_B2\":0.995,\n",
    "    # \"Arc_LS_B2\":1.05,\n",
    "    \"Arc_LS_B2\":1.0,\n",
    "    # \"Arc_LS_B2\":0.995,\n",
    "    \"Sigma_B1\":90, #micron\n",
    "    \"Sigma_B2\":90, #micron\n",
    "    \"nominal_step_size_B1\": 130, #micron\n",
    "    \"nominal_step_size_B2\": 130, #micron\n",
    "    \"cumulative_OD\":False,\n",
    "    \"OD_B1\":[\n",
    "        10,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "    ],\n",
    "    \"OD_B2\":[\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "        0,0,0,\n",
    "    ],\n",
    "    \"Doros_noise_sigma\":0, # micron\n",
    "    \"Arc_noise_sigma\":0, # micron\n",
    "    \"rate_runcertainty_at_head_on\":0.005, \n",
    "    \"beamspot_position_uncertainty\":1, #micron\n",
    "    # \"pos_strategy\":\"doros, middle point\",\n",
    "    \"pos_strategy\":\"doros, avg point\",\n",
    "    # \"pos_strategy\":\"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, avg point\",\n",
    "}\n",
    "\n",
    "np.random.seed(662)\n",
    "\n",
    "sigma_OD = 10\n",
    "od_b1 = np.random.normal(size=15)*sigma_OD\n",
    "od_b2 = np.random.normal(size=15)*sigma_OD\n",
    "# idx = 10#int(np.random.random()*15)\n",
    "# print(idx)\n",
    "# od_b1[idx] += 10\n",
    "\n",
    "params[\"OD_B1\"]= od_b1\n",
    "params[\"OD_B2\"]= od_b2\n",
    "params[\"cumulative_OD\"]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility fitting function using minuit for better error propagation\n",
    "def curve_fit(f, x, y, sigma=None, p0=None, p0_lim=None):\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.ones_like(y)\n",
    "\n",
    "    init_params = {}\n",
    "    if not p0 is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[n]=p0[i]\n",
    "    if not p0_lim is None:\n",
    "        for i, n in enumerate(inspect.getfullargspec(f)[0][1:]):\n",
    "            init_params[\"limit_\"+n]=p0_lim[i]\n",
    "\n",
    "    least_squares = LeastSquares(x, y, sigma, f)\n",
    "\n",
    "    m = Minuit(least_squares, **init_params)\n",
    "\n",
    "    m.migrad()    \n",
    "    try:\n",
    "        cov = np.array(m.matrix())\n",
    "    except:\n",
    "        try:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "        except:\n",
    "            m.hesse()\n",
    "            cov = np.array(m.matrix())\n",
    "        \n",
    "\n",
    "    return m.np_values(), cov\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "def lin(x,a,b):\n",
    "        return a*x+b\n",
    "popt_lin, pcov_lin = curve_fit(lin, range(4), [0,1.1,1.9,3], sigma=[1,1,1,1], p0=[1, 0])\n",
    "print(popt_lin)\n",
    "print(pcov_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nominal beampositions\n",
    "\n",
    "nominal_B1_positions = np.repeat((np.arange(5)*params[\"nominal_step_size_B1\"]),3)\n",
    "scan_pattern = np.tile([-params[\"nominal_step_size_B2\"], 0, params[\"nominal_step_size_B2\"]], 5)\n",
    "nominal_B2_positions = nominal_B1_positions + scan_pattern\n",
    "\n",
    "plt.plot(range(15), nominal_B1_positions, \"or\")\n",
    "plt.plot(range(15), nominal_B2_positions, \"xb\")\n",
    "plt.xlabel('Tick')\n",
    "plt.ylabel('Beam position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OD and BPM\n",
    "if params[\"cumulative_OD\"]:\n",
    "    true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + np.cumsum(params[\"OD_B1\"])\n",
    "    true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + np.cumsum(params[\"OD_B2\"])\n",
    "else:\n",
    "    true_B1_positions = nominal_B1_positions * params[\"Nominal_LS_B1\"] + params[\"OD_B1\"]\n",
    "    true_B2_positions = nominal_B2_positions * params[\"Nominal_LS_B2\"] + params[\"OD_B2\"]\n",
    "\n",
    "doros_B1_positions = true_B1_positions / params[\"Doros_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Doros_noise_sigma\"] \n",
    "doros_B2_positions = true_B2_positions / params[\"Doros_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Doros_noise_sigma\"]\n",
    "\n",
    "arc_B1_positions = true_B1_positions / params[\"Arc_LS_B1\"] + np.random.normal(size=true_B1_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "arc_B2_positions = true_B2_positions / params[\"Arc_LS_B2\"] + np.random.normal(size=true_B2_positions.shape) * params[\"Arc_noise_sigma\"]\n",
    "\n",
    "avg_B1_positions = (doros_B1_positions + arc_B1_positions)/2\n",
    "avg_B2_positions = (doros_B2_positions + arc_B2_positions)/2\n",
    "\n",
    "\n",
    "plt.plot(range(15), doros_B1_positions-nominal_B1_positions+1, \"o-r\")\n",
    "plt.plot(range(15), arc_B1_positions-nominal_B1_positions-1, \"o-b\")\n",
    "plt.plot(range(15), avg_B1_positions-nominal_B1_positions, \"o-y\")\n",
    "plt.xlabel('Tick')\n",
    "plt.ylabel('BPM - nominal')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(15), doros_B2_positions-nominal_B2_positions+1, \"o-r\")\n",
    "plt.plot(range(15), arc_B2_positions-nominal_B2_positions-1, \"o-b\")\n",
    "plt.plot(range(15), avg_B2_positions-nominal_B2_positions, \"o-y\")\n",
    "plt.xlabel('Tick')\n",
    "plt.ylabel('BPM - nominal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_b1(positions, nominal_positions, b1_strategy = \"m\", outliers=0, plot=False):\n",
    "\n",
    "    nominal_step_size = nominal_positions[3] - nominal_positions[0]\n",
    "\n",
    "    if b1_strategy == \"c\":\n",
    "        pos_c   = positions[1::3]        \n",
    "    elif b1_strategy == \"m\":\n",
    "        pos_c = np.array( [ np.mean(positions[3*i:3*i+3]) for i in range(5)] ) \n",
    "    diffs =  np.diff( pos_c )\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if outliers == 0:\n",
    "        avg_step_size = np.mean( diffs )\n",
    "    else:\n",
    "        excluded_indices = []\n",
    "\n",
    "        diffs1  = diffs[:]\n",
    "        for i in range(outliers):\n",
    "            avg     = np.mean( diffs1 )\n",
    "            i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "            if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                break\n",
    "            excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "            diffs1 = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "        avg = np.mean(diffs1)\n",
    "        std = np.std(diffs1)\n",
    "        lim = 3*std\n",
    "        diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "        avg_step_size = np.mean(diffs2)\n",
    "\n",
    "        if plot:\n",
    "            if len(excluded_indices)>0:\n",
    "                plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "            plt.plot([-1,5], [avg, avg], \"-\", color=\"red\")\n",
    "            plt.fill_between([-1,5], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "            plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "    \n",
    "    if plot:\n",
    "        print(\"avg_step_size measured:\", avg_step_size)\n",
    "        plt.plot([-1,5], [avg_step_size, avg_step_size], \"--g\")\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "    od_estimates = diffs - avg_step_size\n",
    "    new_stepsizes = od_estimates + nominal_step_size\n",
    "    new_positions = np.concatenate(([0], np.cumsum(new_stepsizes)))\n",
    "    # take the middle point as reference\n",
    "    new_positions = new_positions - new_positions[2] + nominal_positions[7]\n",
    "\n",
    "    return new_positions\n",
    "\n",
    "# testing\n",
    "# test_positions = np.repeat(np.arange(5),3)*130.0\n",
    "# test_positions[0:2]+=10\n",
    "# print(avg_stepsize_corr_b1(test_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1, plot=True))\n",
    "\n",
    "# test_positions = np.repeat(np.arange(5),3)*130.0\n",
    "# test_positions+= np.random.normal(size=15)*10\n",
    "# print(avg_stepsize_corr_b1(test_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1, plot=True))\n",
    "\n",
    "\n",
    "print(avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=2, plot=True))\n",
    "print(\"avg_step_size doros, theor.:\", params[\"nominal_step_size_B1\"]*params[\"Nominal_LS_B1\"] / params[\"Doros_LS_B1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_stepsize_corr_sep(positions, nominal_positions, steps_to_average=10, outliers=0, plot=False, reference=1):\n",
    "\n",
    "    nominal_step_size = nominal_positions[1] - nominal_positions[0]\n",
    "\n",
    "    diffs = np.diff(positions)\n",
    "    diffs = diffs[ (np.arange(len(diffs)) % 3) != 2]      \n",
    "\n",
    "    if plot:\n",
    "        print(\"diffs\", diffs)\n",
    "        plt.plot(range(len(diffs)), diffs, \"o-b\")\n",
    "\n",
    "    if steps_to_average == 10:\n",
    "        if outliers == 0:\n",
    "            avg_step_size = np.mean( diffs )\n",
    "        else:\n",
    "            # remove 4 outliers\n",
    "            excluded_indices = []\n",
    "            diffs1  =diffs[:]\n",
    "            for i in range(outliers):\n",
    "                avg  = np.mean( diffs1 )\n",
    "                i_extremum = np.argmax(np.abs(diffs1-avg))\n",
    "                if np.abs(diffs1[i_extremum] - avg)<0.01:\n",
    "                    break\n",
    "                excluded_indices.append( np.where(np.isclose(diffs, diffs1[i_extremum]))[0][0] )\n",
    "                diffs1 = diffs1[ np.arange(len(diffs1)) != i_extremum ]\n",
    "            avg = np.mean(diffs1)\n",
    "            std = np.std(diffs1)\n",
    "            lim = 3*std\n",
    "            diffs2 = diffs[ np.abs( diffs-avg )<=lim ]\n",
    "            avg_step_size = np.mean(diffs2)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "                if len(excluded_indices)>0:\n",
    "                    plt.plot(excluded_indices, diffs[np.array(excluded_indices)], \"xr\", markersize=12)\n",
    "                plt.plot([-1,11], [avg, avg], \"-\", color=\"red\")\n",
    "                plt.fill_between([-1,11], [avg-lim, avg-lim], [avg+lim, avg+lim], color=\"red\", alpha=0.2)\n",
    "                plt.plot(np.arange(len(diffs))[ np.abs( diffs-avg )>lim ]+0.3, diffs[ np.abs( diffs-avg )>lim ], \"*m\", markersize=12)\n",
    "                \n",
    "        if plot:\n",
    "            print(\"avg_step_size measured:\", avg_step_size)\n",
    "            plt.plot([-1,11], [avg_step_size, avg_step_size], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "        od_estimates = diffs - avg_step_size\n",
    "        # od_estimates *= nominal_step_size/avg_step_size\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "    elif steps_to_average == 2:\n",
    "\n",
    "        avg_step_sizes = np.repeat([ np.mean(diffs[2*i:2*i+2]) for i in range(5) ], 2)\n",
    "        od_estimates = diffs - avg_step_sizes\n",
    "        new_stepsizes = od_estimates + nominal_step_size\n",
    "\n",
    "        if plot:\n",
    "            print(\"avg_step_sizes measured:\", avg_step_sizes)\n",
    "            for i in range(5):\n",
    "                plt.plot(np.arange(len(avg_step_sizes))[2*i:2*i+2], avg_step_sizes[2*i:2*i+2], \"--g\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    if reference == 1:\n",
    "        # reference is always the middle point\n",
    "        if plot:\n",
    "            print(\"od_estimates\", od_estimates)\n",
    "            print(\"new stepsizes\", new_stepsizes)\n",
    "        result = np.repeat(nominal_positions[1::3], 3)*1.0\n",
    "        for i in range(len(result)):\n",
    "            if i%3==0:\n",
    "                result[i] -= new_stepsizes[i//3*2]\n",
    "            elif i%3==2:\n",
    "                result[i] += new_stepsizes[(i-2)//3*2+1]\n",
    "        return result\n",
    "\n",
    "    elif reference == 2:\n",
    "        return positions - avg_step_size * nominal_positions / nominal_step_size + nominal_positions\n",
    "    \n",
    "\n",
    "# test_positions = np.array(nominal_B2_positions)*1.0\n",
    "# test_positions[0]+=10\n",
    "# print(avg_stepsize_corr_sep(test_positions, nominal_B2_positions, steps_to_average=10, outliers=4, plot=True))\n",
    "\n",
    "# test_positions = np.array(nominal_B2_positions)*1.0\n",
    "# test_positions+= np.cumsum(np.random.normal(size=15)*10)\n",
    "# print(avg_stepsize_corr_sep(test_positions, nominal_B2_positions, steps_to_average=10, outliers=4, plot=True))\n",
    "\n",
    "# test_positions = np.array(nominal_B2_positions)*1.0\n",
    "# test_positions+= np.cumsum(np.random.normal(size=15)*10)\n",
    "# print(avg_stepsize_corr_sep(test_positions, nominal_B2_positions, steps_to_average=2, outliers=0, plot=True))\n",
    "\n",
    "doros_sep   = doros_B1_positions - doros_B2_positions\n",
    "nominal_sep = nominal_B1_positions - nominal_B2_positions\n",
    "print(\"sep doros\",doros_sep)\n",
    "corr_sep = avg_stepsize_corr_sep(doros_sep, nominal_sep, steps_to_average=10, outliers=4, plot=True)\n",
    "print( \"corr_sep\", corr_sep )\n",
    "doros_sep_in_nominal_dims = doros_sep/params[\"Nominal_LS_B1\"] * params[\"Doros_LS_B1\"]\n",
    "print(\"doros_sep_in_nominal_dims\", doros_sep_in_nominal_dims)\n",
    "\n",
    "print(\"first half differences\", np.diff(corr_sep)[0::3] - np.diff(doros_sep_in_nominal_dims)[0::3])\n",
    "print(\"second half differences\",np.diff(corr_sep)[1::3] - np.diff(doros_sep_in_nominal_dims)[1::3])\n",
    "\n",
    "print(\"avg_step_size doros, theor.:\", params[\"nominal_step_size_B2\"]*params[\"Nominal_LS_B2\"] / params[\"Doros_LS_B2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OD correction of nominal\n",
    "\n",
    "# this part needs to compute the followings:\n",
    "# analysis_B1_positions or analysis_separations\n",
    "# analysis_B2_positions or analysis_separations\n",
    "# analysis_B1_5positions\n",
    "\n",
    "# maybe we don't need to do step size correction for the scanning beam at all! \n",
    "# after all this method should be only sensitive to the LS of B1!\n",
    "# in fact, probably we should always just use avg for the scanning beam, as that is the safest and most accrate probably\n",
    "\n",
    "# the miniscan deltas are from the bpm-s directly \n",
    "\n",
    "if params[\"pos_strategy\"]==\"nominal, middle point\":\n",
    "    analysis_separations   = nominal_B1_positions - nominal_B2_positions\n",
    "    analysis_B1_5positions = nominal_B1_positions[1::3]\n",
    "elif params[\"pos_strategy\"]==\"nominal, avg point\":\n",
    "    analysis_separations   = nominal_B1_positions - nominal_B2_positions\n",
    "    analysis_B1_5positions = np.array([ np.mean(nominal_B1_positions[3*i:3*i+3]) for i in range(5)])\n",
    "elif params[\"pos_strategy\"]==\"doros, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_B1_5positions = doros_B1_positions[1::3]\n",
    "elif params[\"pos_strategy\"]==\"doros, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_B1_5positions = np.array([ np.mean(doros_B1_positions[3*i:3*i+3]) for i in range(5)])\n",
    "#######################\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 2, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10 outlier4, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier 1, sep stepsize 10, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=2)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, avg point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"m\", outliers=1)\n",
    "#######################\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 2, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=2, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize, sep stepsize 10 outlier4, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=0)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier 1, sep stepsize 10, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=0)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier4, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=4)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)\n",
    "elif params[\"pos_strategy\"]==\"doros, b1 stepsize outlier1, sep stepsize 10 outlier2, middle point\":\n",
    "    analysis_separations   = doros_B1_positions - doros_B2_positions\n",
    "    analysis_separations   = avg_stepsize_corr_sep(analysis_separations, nominal_B2_positions, steps_to_average=10, outliers=2)\n",
    "    analysis_B1_5positions = avg_stepsize_corr_b1(doros_B1_positions, nominal_B1_positions, b1_strategy = \"c\", outliers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## beamspot location \n",
    "true_beamspot_positions = ( \n",
    "        true_B1_positions/params[\"Sigma_B1\"]**2 + \n",
    "        true_B2_positions/params[\"Sigma_B2\"]**2\n",
    "    )/(params[\"Sigma_B1\"]**-2+params[\"Sigma_B2\"]**-2)\n",
    "\n",
    "\n",
    "plt.plot(range(15), true_B1_positions, \"or\")\n",
    "plt.plot(range(15), true_B2_positions, \"xb\")\n",
    "plt.plot(range(15), true_beamspot_positions, \"xg\")\n",
    "plt.xlabel('Tick')\n",
    "plt.ylabel('Beam position / bs position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rates\n",
    "true_rates     = np.exp(-0.5 * (true_B1_positions-true_B2_positions)**2 / (params[\"Sigma_B1\"]**2+params[\"Sigma_B2\"]**2) )\n",
    "true_rates_unc = true_rates**0.5 * np.max(true_rates)**0.5 * params[\"rate_runcertainty_at_head_on\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate head-on beamspot position\n",
    "\n",
    "def get_headon_position(rates, rate_unc, separations, beamspot_positions ):\n",
    "\n",
    "    def sg(x,a,m,s):\n",
    "        return a*np.exp(-0.5*((x-m)/s)**2)\n",
    "    \n",
    "    a0 = np.max(rates)\n",
    "    m0 = separations[1]\n",
    "    s0 = np.abs(separations[1] - separations[0])\n",
    "    popt_sg, pcov_sg = curve_fit(sg, separations, rates, sigma=rate_unc, \n",
    "                                    p0=[a0, m0, s0 ],\n",
    "                                    p0_lim = [\n",
    "                                        [a0/2, a0*2],\n",
    "                                        [m0-s0*2, m0+s0*2],\n",
    "                                        [s0/2, s0*2],\n",
    "                                    ] )\n",
    "\n",
    "    mu               = popt_sg[1]\n",
    "\n",
    "    def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "    popt_lin, pcov_lin = curve_fit(lin, separations, beamspot_positions, sigma=[params[\"beamspot_position_uncertainty\"]]*3, p0=[1, 0])\n",
    "    a = popt_lin[0]\n",
    "    b = popt_lin[1]\n",
    "\n",
    "    # compute result uncertainty\n",
    "    if np.allclose(pcov_lin, 0):\n",
    "        std = a*pcov_sg[1,1]**0.5\n",
    "    else:\n",
    "        mu_randomized = mu + pcov_sg[1,1]**0.5*np.random.normal(size=1000)\n",
    "        try:\n",
    "            pcov_lin_sqrt = np.linalg.cholesky(pcov_lin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(pcov_lin)\n",
    "            sys.exit()\n",
    "\n",
    "        ab_randomized = popt_lin[:,np.newaxis] + np.einsum(\"ij,jk\", pcov_lin_sqrt, np.random.normal(size=(2,1000)))\n",
    "        std = np.std( ab_randomized[0,:]*mu_randomized + ab_randomized[1,:] )\n",
    "\n",
    "    if std == 0:\n",
    "        std = 1e-6\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    " \n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('sep')\n",
    "    ax1.set_ylabel('Rate', color = color)\n",
    "    ax1.errorbar(separations, rates, yerr=rate_unc, fmt=\"o\", color = color)\n",
    "    x = np.linspace(separations[0] - (separations[-1]-separations[0])*0.2, separations[-1] + (separations[-1]-separations[0])*0.2, 100)\n",
    "    ax1.plot(x, sg(x, *popt_sg ), color = color)\n",
    "    ax1.tick_params(axis ='y', labelcolor = color)\n",
    "\n",
    "    ax1.plot([mu, mu], [min(rates)/1.1, max(rates)*1.1], \"k--\")\n",
    "    \n",
    "    # Adding Twin Axes to plot using dataset_2\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    color = 'tab:green'\n",
    "    ax2.set_ylabel('Beamspot positions', color = color)\n",
    "    ax2.errorbar(separations, beamspot_positions, yerr=[params[\"beamspot_position_uncertainty\"]]*3, fmt=\"o\", color = color)\n",
    "    ax2.plot(x, lin(x, *popt_lin ), color = color)\n",
    "    ax2.tick_params(axis ='y', labelcolor = color)\n",
    "\n",
    "    ax2.plot([min(separations), max(separations)], [a*mu+b]*2, \"k--\")\n",
    "\n",
    "    return a*mu+b, std\n",
    "\n",
    "\n",
    "computed_head_on_bs_position = []\n",
    "computed_head_on_bs_position_unc = []\n",
    "for i in range(5):\n",
    "\n",
    "    v, u = get_headon_position(\n",
    "        true_rates[3*i:3*i+3],\n",
    "        true_rates_unc[3*i:3*i+3],\n",
    "        # analysis_B1_positions[3*i:3*i+3] - analysis_B2_positions[3*i:3*i+3],\n",
    "        analysis_separations[3*i:3*i+3],\n",
    "        true_beamspot_positions[3*i:3*i+3])\n",
    "    computed_head_on_bs_position.append(v) \n",
    "    computed_head_on_bs_position_unc.append(u)\n",
    "\n",
    "print(computed_head_on_bs_position)\n",
    "print(computed_head_on_bs_position_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_B1_5positions = analysis_B1_5positions[:-1]\n",
    "# computed_head_on_bs_position = computed_head_on_bs_position[:-1]\n",
    "# computed_head_on_bs_position_unc = computed_head_on_bs_position_unc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lin(x,a,b):\n",
    "        return a*x+b\n",
    "\n",
    "\n",
    "a0 = (computed_head_on_bs_position[-1]-computed_head_on_bs_position[0])/(analysis_B1_5positions[-1]-analysis_B1_5positions[0])\n",
    "b0 = 0\n",
    "popt_lin, pcov_lin = curve_fit(lin, analysis_B1_5positions, computed_head_on_bs_position, sigma=computed_head_on_bs_position_unc, p0=[a0, b0])\n",
    "a = popt_lin[0]\n",
    "b = popt_lin[1]\n",
    "\n",
    "print(\"computed LSC\", a, \"+/-\", pcov_lin[0,0]**0.5)\n",
    "\n",
    "liml = np.min(analysis_B1_5positions) - 0.2 * (np.max(analysis_B1_5positions)-np.min(analysis_B1_5positions))\n",
    "limu = np.max(analysis_B1_5positions) + 0.2 * (np.max(analysis_B1_5positions)-np.min(analysis_B1_5positions))\n",
    "x = np.linspace(liml, limu, 2)\n",
    "plt.plot(x, lin(x,a-1,b), \"b-\")\n",
    "plt.errorbar(analysis_B1_5positions, computed_head_on_bs_position - analysis_B1_5positions, yerr=computed_head_on_bs_position_unc, fmt=\"or\")\n",
    "\n",
    "\n",
    "plt.xlabel('\"'+params[\"pos_strategy\"] + '\" position')\n",
    "plt.ylabel('Beamspot position - X values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
